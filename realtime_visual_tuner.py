import cv2
import numpy as np
import mediapipe as mp
import time
import os
import math
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

# =========================================================
# âš™ï¸ ì„¤ì • ë° ìƒìˆ˜
# =========================================================
# ëª¨ë¸ ê²½ë¡œ (ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
MODEL_PATH = os.path.join("app", "engines", "visual", "models", "face_landmarker.task")

# í™”ë©´ ì„¤ì •
MIRROR_VIEW = True  # ê±°ìš¸ ëª¨ë“œ

# --- ì„ê³„ê°’ ì„¤ì • ---
# 1. Head
HEAD_NORMAL_LIMIT = 2.5   # ì •ìƒ ë²”ìœ„ (ë„)
HEAD_MAJOR_LIMIT = 10.0   # ì‹¬ê°í•œ ì´íƒˆ ê¸°ì¤€ (ë„)
HEAD_TIME_LIMIT = 3.0     # ê²½ë¯¸í•œ ì´íƒˆ í—ˆìš© ì‹œê°„ (ì´ˆ)

# 2. Blink
BLINK_THRESH = 0.5        # ëˆˆ ê°ìŒ íŒì • Score
BPM_MIN = 10              # ì •ìƒ ìµœì†Œ BPM
BPM_MAX = 30              # ì •ìƒ ìµœëŒ€ BPM

# 3. Smile
SMILE_THRESH = 0.5        # ë¯¸ì†Œ íŒì • Score

# 4. Gaze (Iris)
GAZE_ENTER = 0.18
GAZE_EXIT = 0.10
L_OUTER, L_INNER = 33, 133
R_OUTER, R_INNER = 263, 362
L_IRIS = [468, 469, 470, 471, 472]
R_IRIS = [473, 474, 475, 476, 477]

# =========================================================
# ğŸ› ï¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =========================================================
def _lm_px(lm, w, h):
    return np.array([lm.x * w, lm.y * h], dtype=np.float32)

def _iris_center(landmarks, w, h, idxs):
    pts = []
    for i in idxs:
        pts.append(_lm_px(landmarks[i], w, h))
    return np.mean(np.stack(pts, axis=0), axis=0)

def _eye_axis(landmarks, w, h, outer_idx, inner_idx):
    p_outer = _lm_px(landmarks[outer_idx], w, h)
    p_inner = _lm_px(landmarks[inner_idx], w, h)
    eye_center = (p_outer + p_inner) * 0.5
    v = (p_inner - p_outer)
    norm = np.linalg.norm(v) + 1e-6
    u = v / norm
    return eye_center, u, norm

def _iris_shift_1d(iris_c, eye_center, eye_u, eye_width):
    rel = iris_c - eye_center
    shift = float(np.dot(rel, eye_u)) / max(eye_width, 1.0)
    return shift

def calculate_roll(p1, p2):
    # p1: Head(10), p2: Nose(1)
    dx = p1.x - p2.x
    dy = p1.y - p2.y
    angle_deg = math.degrees(math.atan2(dy, dx)) + 90
    return angle_deg

def draw_korean_text(img, text, pos, color, scale=0.6):
    # OpenCVëŠ” í•œê¸€ ì§€ì›ì´ ì•ˆë˜ë¯€ë¡œ ì˜ë¬¸ìœ¼ë¡œ ëŒ€ì²´í•˜ê±°ë‚˜, PILì„ ì¨ì•¼ í•¨.
    # ì—¬ê¸°ì„œëŠ” ë¹ ë¥¸ ì‹¤í–‰ì„ ìœ„í•´ ì˜ë¬¸ í‘œê¸° + ì½˜ì†” ë¡œê·¸ë¥¼ ê°€ì •.
    cv2.putText(img, text, pos, cv2.FONT_HERSHEY_SIMPLEX, scale, color, 2)

# =========================================================
# ğŸ§  ë¶„ì„ í´ë˜ìŠ¤ (ìƒíƒœ ê´€ë¦¬)
# =========================================================
class InterviewAnalyzer:
    def __init__(self):
        self.start_time = time.time()
        
        # --- Head State ---
        self.score_head = 50
        self.head_violations = {
            "short_minor": 0, # 3ì´ˆ ì´í•˜, 2.5~10ë„
            "long_minor": 0,  # 3ì´ˆ ì´ˆê³¼, 2.5~10ë„
            "major": 0        # 10ë„ ì´ìƒ
        }
        self.curr_head_start = None
        self.curr_head_max_angle = 0.0
        self.is_head_deviated = False

        # --- Smile State ---
        self.score_smile = 0 # ê¸°ë³¸ 0 (í•œë²ˆì´ë¼ë„ ì›ƒìœ¼ë©´ 5)
        self.has_smiled = False

        # --- Blink State ---
        self.score_blink = 10
        self.blink_count = 0
        self.is_eye_closed = False
        self.bad_bpm_duration = 0.0 # BPMì´ ë¹„ì •ìƒì´ì—ˆë˜ ëˆ„ì  ì‹œê°„
        self.prev_bpm_status = "NORMAL" # NORMAL, FAST, SLOW

        # --- Gaze State ---
        self.score_gaze = 20
        self.base_L = None
        self.base_R = None
        self.calib_samples = []
        self.gaze_state = "CENTER"
        self.gaze_off_start = None
        self.total_gaze_off_time = 0.0
        self.long_gaze_off_count = 0 # 2ì´ˆ ì´ˆê³¼ ì´íƒˆ íšŸìˆ˜

        # --- Global ---
        self.base_score = 15

    def update(self, landmarks, blendshapes, w, h):
        now = time.time()
        elapsed = now - self.start_time
        if elapsed < 0.1: return # ì‹œì‘ ì§í›„ ìŠ¤í‚µ

        # ---------------------------
        # 1. Head Analysis
        # ---------------------------
        nose = landmarks[1]
        head_top = landmarks[10]
        roll = calculate_roll(head_top, nose)
        abs_roll = abs(roll)

        if abs_roll > HEAD_NORMAL_LIMIT:
            if not self.is_head_deviated:
                self.is_head_deviated = True
                self.curr_head_start = now
                self.curr_head_max_angle = abs_roll
            else:
                self.curr_head_max_angle = max(self.curr_head_max_angle, abs_roll)
        else:
            if self.is_head_deviated:
                # ì´íƒˆ ì¢…ë£Œ -> í‰ê°€
                duration = now - self.curr_head_start
                max_angle = self.curr_head_max_angle
                
                if max_angle > HEAD_MAJOR_LIMIT:
                    self.head_violations["major"] += 1
                elif duration > HEAD_TIME_LIMIT:
                    self.head_violations["long_minor"] += 1
                else:
                    self.head_violations["short_minor"] += 1
                
                self.is_head_deviated = False

        # Head Score Calculation
        deduction_head = 0
        # (1) Short Minor: 3íšŒ ë¬´ë£Œ, 4íšŒë¶€í„° íšŒë‹¹ -5
        deduction_head += max(0, self.head_violations["short_minor"] - 3) * 5
        # (2) Long Minor: íšŒë‹¹ -10
        deduction_head += self.head_violations["long_minor"] * 10
        # (3) Major: 1íšŒ ë¬´ë£Œ, 2íšŒë¶€í„° íšŒë‹¹ -20
        deduction_head += max(0, self.head_violations["major"] - 1) * 20
        
        self.score_head = max(0, 50 - min(50, deduction_head))

        # ---------------------------
        # 2. Smile Analysis
        # ---------------------------
        smile_score = 0.0
        if blendshapes:
            s_left = next((x.score for x in blendshapes if x.category_name == 'mouthSmileLeft'), 0.0)
            s_right = next((x.score for x in blendshapes if x.category_name == 'mouthSmileRight'), 0.0)
            smile_score = (s_left + s_right) / 2.0
        
        if smile_score > SMILE_THRESH:
            self.has_smiled = True
        
        self.score_smile = 5 if self.has_smiled else 0

        # ---------------------------
        # 3. Blink Analysis
        # ---------------------------
        eye_score = 0.0
        if blendshapes:
            b_left = next((x.score for x in blendshapes if x.category_name == 'eyeBlinkLeft'), 0.0)
            b_right = next((x.score for x in blendshapes if x.category_name == 'eyeBlinkRight'), 0.0)
            eye_score = (b_left + b_right) / 2.0

        is_closed = eye_score > BLINK_THRESH
        if is_closed and not self.is_eye_closed:
            self.blink_count += 1
        self.is_eye_closed = is_closed

        # BPM ê³„ì‚° ë° ìƒíƒœ ëˆ„ì 
        bpm = self.blink_count / (elapsed / 60.0) if elapsed > 1 else 0
        
        bpm_status = "NORMAL"
        if elapsed > 5: # 5ì´ˆ ì´í›„ë¶€í„° íŒì •
            if bpm > BPM_MAX: bpm_status = "FAST"
            elif bpm < BPM_MIN: bpm_status = "SLOW"
        
        if bpm_status != "NORMAL":
            # ì´ì „ í”„ë ˆì„ ì‹œê°„ì°¨(ì•½ 0.033ì´ˆ)ë§Œí¼ ëˆ„ì 
            # ì •í™•ë„ë¥¼ ìœ„í•´ ì‹¤ì œ dtë¥¼ ì“°ë©´ ì¢‹ì§€ë§Œ ì—¬ê¸°ì„  ê·¼ì‚¬ì¹˜
            self.bad_bpm_duration += 0.033 

        # Blink Score Calc
        # ë¹„ì •ìƒ ë¹„ìœ¨ ê³„ì‚°
        bad_ratio = self.bad_bpm_duration / elapsed
        blink_deduction = 0
        if bad_ratio >= 0.1: # 10% ì´ìƒ ë¹„ì •ìƒì´ë©´ ë¶€ë¶„ ê°ì 
            blink_deduction = 5
        if bad_ratio > 0.5: # 50% ì´ìƒ(ì „ì²´ì ìœ¼ë¡œ) ë¹„ì •ìƒì´ë©´ ì¶”ê°€ ê°ì  -> ì´ 10ì 
            blink_deduction = 10
        
        # ìµœëŒ€ ê°ì  -15 ì œí•œì´ ìˆì§€ë§Œ í•­ëª© ë§Œì ì´ 10ì ì´ë¯€ë¡œ 0ì  í•˜í•œì„ 
        self.score_blink = max(0, 10 - blink_deduction)


        # ---------------------------
        # 4. Gaze Analysis
        # ---------------------------
        # (Iris tracking logic from snippet)
        iris_L = _iris_center(landmarks, w, h, L_IRIS)
        iris_R = _iris_center(landmarks, w, h, R_IRIS)
        
        label_gaze = "N/A"
        
        if iris_L is not None and iris_R is not None:
            cL, uL, wL = _eye_axis(landmarks, w, h, L_OUTER, L_INNER)
            cR, uR, wR = _eye_axis(landmarks, w, h, R_OUTER, R_INNER)
            sL = _iris_shift_1d(iris_L, cL, uL, wL)
            sR = _iris_shift_1d(iris_R, cR, uR, wR)

            if len(self.calib_samples) < 30:
                self.calib_samples.append((sL, sR))
                if len(self.calib_samples) == 30:
                    self.base_L = sum(x for x, _ in self.calib_samples) / 30
                    self.base_R = sum(y for _, y in self.calib_samples) / 30
                label_gaze = "CALIB"
            else:
                dL = sL - self.base_L
                dR = sR - self.base_R
                d = dL if abs(dL) >= abs(dR) else dR
                if MIRROR_VIEW: d = -d # ê±°ìš¸ëª¨ë“œ ë³´ì •

                # State Machine
                if self.gaze_state == "CENTER":
                    if d > GAZE_ENTER: 
                        self.gaze_state = "RIGHT"
                        self.gaze_off_start = now
                    elif d < -GAZE_ENTER: 
                        self.gaze_state = "LEFT"
                        self.gaze_off_start = now
                else:
                    if abs(d) < GAZE_EXIT:
                        # ì´íƒˆ ì¢…ë£Œ -> ì‹œê°„ ê³„ì‚°
                        if self.gaze_off_start:
                            off_dur = now - self.gaze_off_start
                            self.total_gaze_off_time += off_dur
                            if off_dur > 2.0: # 2ì´ˆ ì´ˆê³¼ ì´íƒˆ
                                self.long_gaze_off_count += 1
                        self.gaze_state = "CENTER"
                        self.gaze_off_start = None
                    else:
                        # ì´íƒˆ ì¤‘ -> í˜„ì¬ ì‹œê°„ë„ ëˆ„ì ì— í¬í•¨(ì‹¤ì‹œê°„ì„±ì„ ìœ„í•´)
                        pass
                
                label_gaze = self.gaze_state

        # Gaze Score Calc
        gaze_deduction = 0
        
        # (1) ì „ì²´ ì‹œê°„ì˜ 10% ì´ìƒ ì´íƒˆ
        # í˜„ì¬ ì§„í–‰ì¤‘ì¸ ì´íƒˆ ì‹œê°„ë„ í•©ì‚°
        current_off_add = 0
        if self.gaze_state != "CENTER" and self.gaze_off_start:
            current_off_add = now - self.gaze_off_start
        
        total_off_ratio = (self.total_gaze_off_time + current_off_add) / max(elapsed, 1)
        if total_off_ratio >= 0.10:
            gaze_deduction += 10
        
        # (2) 2ì´ˆ ì´ˆê³¼ ì´íƒˆ íšŸìˆ˜ (íšŒë‹¹ -5, ìµœëŒ€ -10)
        long_off_deduction = min(10, self.long_gaze_off_count * 5)
        gaze_deduction += long_off_deduction

        self.score_gaze = max(0, 20 - gaze_deduction)

        return {
            "roll": roll,
            "bpm": bpm,
            "gaze": label_gaze,
            "total_score": self.base_score + self.score_head + self.score_smile + self.score_blink + self.score_gaze,
            "scores": (self.score_head, self.score_smile, self.score_blink, self.score_gaze),
            "counts": (self.head_violations, self.blink_count, self.long_gaze_off_count)
        }

# =========================================================
# ğŸš€ ë©”ì¸ ì‹¤í–‰
# =========================================================
def main():
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ ëª¨ë¸ ì—†ìŒ: {MODEL_PATH}")
        return

    base_options = python.BaseOptions(model_asset_path=MODEL_PATH)
    options = vision.FaceLandmarkerOptions(
        base_options=base_options,
        running_mode=vision.RunningMode.VIDEO,
        num_faces=1,
        output_face_blendshapes=True
    )
    landmarker = vision.FaceLandmarker.create_from_options(options)

    cap = cv2.VideoCapture(0)
    analyzer = InterviewAnalyzer()

    while True:
        ret, frame = cap.read()
        if not ret: break
        
        if MIRROR_VIEW: frame = cv2.flip(frame, 1)
        h, w = frame.shape[:2]
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        ts = int((time.time() - analyzer.start_time) * 1000)

        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb)
        result = landmarker.detect_for_video(mp_image, ts)

        data = None
        if result.face_landmarks:
            lm = result.face_landmarks[0]
            bs = result.face_blendshapes[0]
            data = analyzer.update(lm, bs, w, h)
            
            # --- ì‹œê°í™” ---
            # 1. ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸° (ì½”, ì •ìˆ˜ë¦¬, ëˆˆ)
            nose = _lm_px(lm[1], w, h)
            head = _lm_px(lm[10], w, h)
            cv2.line(frame, (int(nose[0]), int(nose[1])), (int(head[0]), int(head[1])), (0, 255, 255), 2)
            
            # 2. ì •ë³´ íŒ¨ë„
            overlay = frame.copy()
            cv2.rectangle(overlay, (0, 0), (350, h), (0, 0, 0), -1)
            frame = cv2.addWeighted(overlay, 0.6, frame, 0.4, 0)
            
            s_head, s_smile, s_blink, s_gaze = data["scores"]
            violations, blinks, gaze_long = data["counts"]
            
            y = 40
            draw_korean_text(frame, f"TOTAL: {int(data['total_score'])}/100", (10, y), (0, 255, 0), 1.0)
            
            y += 40
            col = (255, 255, 255)
            draw_korean_text(frame, f"[Head] {s_head}/50 (Ang:{data['roll']:.1f})", (10, y), col)
            y += 25
            draw_korean_text(frame, f" - Short(>3): {violations['short_minor']}", (20, y), (200, 200, 200), 0.5)
            y += 20
            draw_korean_text(frame, f" - Long(>3s): {violations['long_minor']}", (20, y), (200, 200, 200), 0.5)
            y += 20
            draw_korean_text(frame, f" - Major(>10): {violations['major']}", (20, y), (200, 200, 200), 0.5)

            y += 40
            draw_korean_text(frame, f"[Smile] {s_smile}/5", (10, y), col)
            y += 25
            status = "SMILED!" if s_smile > 0 else "NO SMILE"
            draw_korean_text(frame, f" - {status}", (20, y), (200, 200, 200), 0.5)

            y += 40
            draw_korean_text(frame, f"[Blink] {s_blink}/10 (BPM:{data['bpm']:.1f})", (10, y), col)
            y += 25
            draw_korean_text(frame, f" - Count: {blinks}", (20, y), (200, 200, 200), 0.5)

            y += 40
            draw_korean_text(frame, f"[Gaze] {s_gaze}/20 ({data['gaze']})", (10, y), col)
            y += 25
            draw_korean_text(frame, f" - Long Off(>2s): {gaze_long}", (20, y), (200, 200, 200), 0.5)

        else:
            cv2.putText(frame, "NO FACE", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        cv2.imshow("Interview AI Analyst", frame)
        if cv2.waitKey(1) & 0xFF == 27: break

    cap.release()
    cv2.destroyAllWindows()
    landmarker.close()

if __name__ == "__main__":
    main()