import cv2
import numpy as np
import mediapipe as mp
import time
import os
from collections import deque
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

# =========================================================
# âš™ï¸ ì„¤ì • ë° ìƒìˆ˜ (engine.pyì™€ ë™ì¼í•˜ê²Œ ë§ì¶¤)
# =========================================================
MODULE_NAME = "visual_tuner"
# ëª¨ë¸ ê²½ë¡œ: í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ì¶° ì„¤ì • (ì‹¤í–‰ ìœ„ì¹˜ ê¸°ì¤€)
MODEL_PATH = os.path.join("app", "engines", "visual", "models", "face_landmarker.task")

NOSE_CENTER_RANGE = (0.40, 0.60)  # ì¤‘ì•™ ì¸ì • ë²”ìœ„ (40% ~ 60%)
STD_REF = 0.02                    # ê³ ê°œ ì›€ì§ì„ ê¸°ì¤€ê°’
NOSE_LANDMARK_IDX = 0             # ì½” ë ëœë“œë§ˆí¬ ì¸ë±ìŠ¤

# =========================================================
# ğŸ› ï¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =========================================================
def _clamp01(x: float) -> float:
    return float(max(0.0, min(1.0, x)))

def draw_text(img, text, x, y, color=(0, 255, 0), font_scale=0.6):
    cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), 3) # ê·¸ë¦¼ì
    cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)

def main():
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
        print("   app/engines/visual/models/ í´ë”ì— face_landmarker.task íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    # 1. Face Landmarker ì´ˆê¸°í™”
    base_options = python.BaseOptions(model_asset_path=MODEL_PATH)
    options = vision.FaceLandmarkerOptions(
        base_options=base_options,
        running_mode=vision.RunningMode.VIDEO, # ì›¹ìº  ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ë¥¼ ìœ„í•´ VIDEO ëª¨ë“œ ì‚¬ìš© (í”„ë ˆì„ ìˆœì°¨ ì£¼ì…)
        num_faces=1,
        output_face_blendshapes=False,
        output_facial_transformation_matrixes=False,
    )
    landmarker = vision.FaceLandmarker.create_from_options(options)

    # 2. ì›¹ìº  ì‹¤í–‰
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("âœ… ì‹¤ì‹œê°„ ë¶„ì„ ì‹œì‘! (ì¢…ë£Œí•˜ë ¤ë©´ 'q'ë¥¼ ëˆ„ë¥´ì„¸ìš”)")

    # 3. ë°ì´í„° ëˆ„ì  ë³€ìˆ˜ (ì„¸ì…˜ ì „ì²´ í‰ê·  ê³„ì‚°ìš©)
    history_face_present = []
    history_nose_x = []
    history_diffs = [] # ì›€ì§ì„ í‘œì¤€í¸ì°¨ ê³„ì‚°ìš©
    
    prev_nose_x = None
    start_time = time.time()

    # í”„ë ˆì„ ë£¨í”„
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # ë¯¸ëŸ¬ë§ (ê±°ìš¸ ëª¨ë“œ)
        frame = cv2.flip(frame, 1)
        h, w, _ = frame.shape
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # í˜„ì¬ ì‹œê°„ (ms)
        timestamp_ms = int((time.time() - start_time) * 1000)
        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb)

        # ------------------------------------------------
        # ğŸ” ê°ì§€ ì‹¤í–‰
        # ------------------------------------------------
        result = landmarker.detect_for_video(mp_image, timestamp_ms)

        current_nose_x = None
        is_face_present = False

        if result.face_landmarks:
            is_face_present = True
            nose = result.face_landmarks[0][NOSE_LANDMARK_IDX]
            current_nose_x = nose.x # 0.0 ~ 1.0 ì •ê·œí™”ëœ ì¢Œí‘œ
            
            # í™”ë©´ ê·¸ë¦¬ê¸° (ì½” ìœ„ì¹˜)
            pixel_x, pixel_y = int(nose.x * w), int(nose.y * h)
            cv2.circle(frame, (pixel_x, pixel_y), 8, (0, 0, 255), -1) # ë¹¨ê°„ ì 
            
            # ì¤‘ì•™ ë²”ìœ„ ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë…¹ìƒ‰ ë°•ìŠ¤)
            x1, x2 = int(w * NOSE_CENTER_RANGE[0]), int(w * NOSE_CENTER_RANGE[1])
            overlay = frame.copy()
            cv2.rectangle(overlay, (x1, 0), (x2, h), (0, 255, 0), -1)
            cv2.addWeighted(overlay, 0.2, frame, 0.8, 0, frame) # íˆ¬ëª…í•˜ê²Œ í‘œì‹œ

        # ------------------------------------------------
        # ğŸ“Š ì§€í‘œ ì‹¤ì‹œê°„ ê³„ì‚° (ëˆ„ì  ë°ì´í„° ê¸°ë°˜)
        # ------------------------------------------------
        history_face_present.append(is_face_present)
        history_nose_x.append(current_nose_x)

        # ì›€ì§ì„ ì°¨ì´ ê³„ì‚°
        if current_nose_x is not None:
            if prev_nose_x is not None:
                diff = abs(current_nose_x - prev_nose_x)
                history_diffs.append(diff)
            prev_nose_x = current_nose_x
        else:
            prev_nose_x = None # ì–¼êµ´ ë†“ì¹˜ë©´ íë¦„ ëŠê¸°

        # (1) í™”ë©´ ì‘ì‹œìœ¨ (Face Presence Ratio)
        metrics_presence = sum(history_face_present) / len(history_face_present) if history_face_present else 0.0
        
        # (2) ì¤‘ì•™ ìœ ì§€ìœ¨ (Head Center Ratio) - ì–¼êµ´ì´ ê°ì§€ëœ í”„ë ˆì„ ì¤‘ ì¤‘ì•™ì— ìˆëŠ” ë¹„ìœ¨
        valid_x = [x for x in history_nose_x if x is not None]
        center_count = sum(1 for x in valid_x if NOSE_CENTER_RANGE[0] <= x <= NOSE_CENTER_RANGE[1])
        metrics_center = center_count / len(valid_x) if valid_x else 0.0

        # (3) ê³ ê°œ ì›€ì§ì„ (Head Movement STD)
        std_raw = np.std(history_diffs) if history_diffs else 0.0
        metrics_movement = _clamp01(float(std_raw) / STD_REF)

        # ------------------------------------------------
        # ğŸ“º í™”ë©´ì— ì •ë³´ ì¶œë ¥
        # ------------------------------------------------
        # ìƒíƒœ íŒ¨ë„ ë°°ê²½
        cv2.rectangle(frame, (10, 10), (450, 180), (0, 0, 0), -1) # ê²€ì€ ë°°ê²½
        
        # í˜„ì¬ ìƒíƒœ í‘œì‹œ
        status_color = (0, 255, 0) if is_face_present else (0, 0, 255)
        status_text = f"Face: {'DETECTED' if is_face_present else 'LOST'}"
        draw_text(frame, status_text, 30, 40, status_color)
        
        if current_nose_x:
            nose_text = f"Nose X: {current_nose_x:.3f} ({'CENTER' if NOSE_CENTER_RANGE[0]<=current_nose_x<=NOSE_CENTER_RANGE[1] else 'OUT'})"
            draw_text(frame, nose_text, 250, 40, (255, 255, 0))

        # ëˆ„ì  ì§€í‘œ (engine.py ë¡œì§ê³¼ ë™ì¼)
        cv2.line(frame, (20, 55), (440, 55), (255, 255, 255), 1)
        
        # 1. Presence Ratio
        p_color = (0, 255, 0) if metrics_presence >= 0.8 else (0, 0, 255)
        draw_text(frame, f"1. Presence Ratio: {metrics_presence:.3f} (Target > 0.8)", 30, 80, p_color)

        # 2. Center Ratio
        c_color = (0, 255, 0) if metrics_center >= 0.6 else (0, 0, 255)
        draw_text(frame, f"2. Center Ratio  : {metrics_center:.3f} (Target > 0.6)", 30, 115, c_color)

        # 3. Movement STD
        # ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ (0ì— ê°€ê¹Œìš°ë©´ ì•ˆì •ì )
        m_color = (0, 255, 0) if metrics_movement < 0.3 else (0, 0, 255) # ì„ì˜ ê¸°ì¤€ 0.3
        draw_text(frame, f"3. Movement STD  : {metrics_movement:.3f} (Low is Better)", 30, 150, m_color)


        cv2.imshow('Visual Metrics Tuner', frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
    landmarker.close()

if __name__ == "__main__":
    main()