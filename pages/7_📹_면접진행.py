import streamlit as st
import streamlit.components.v1 as components
import requests
import time
import cv2
import numpy as np

import base64

# -----------------------------
# 1. ë¡œê·¸ì¸ ë° ì„¸ì…˜ ì²´í¬
# -----------------------------
if not st.session_state.get('user') or not st.session_state.get('token'):
    st.warning("ë¡œê·¸ì¸ì´ í•„ìš”í•œ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.")
    st.switch_page("pages/3_ğŸ”_ë¡œê·¸ì¸.py")
    st.stop()

# -----------------------------
# 2. ë¶„ì„ ì‹¤íŒ¨ UI í•¨ìˆ˜
# -----------------------------
def display_analysis_failure(answer_id, error_msg="ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì´ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤."):
    st.error("âš ï¸ AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    with st.expander("ìƒì„¸ ì—ëŸ¬ ë‚´ìš© í™•ì¸"):
        st.write(f"**ë‹µë³€ ID:** {answer_id}")
        st.write(f"**ì˜¤ë¥˜ ë©”ì‹œì§€:** {error_msg}")
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ”„ ë¶„ì„ ë‹¤ì‹œ ì‹œë„", use_container_width=True):
            st.rerun()
    with col2:
        if st.button("ğŸ“¹ ë‹µë³€ ë‹¤ì‹œ í•˜ê¸°", use_container_width=True, type="primary"):
            st.rerun()

# -----------------------------
# 3. API ë° ì„¸ì…˜ ì´ˆê¸°í™”
# -----------------------------
API_BASE = "http://localhost:8000"
headers = {"Authorization": f"Bearer {st.session_state.get('token')}"}

st.title("ğŸ“¹ AI ì‹¤ì‹œê°„ ëª¨ì˜ë©´ì ‘")

# ë©´ì ‘ ìƒíƒœ ì´ˆê¸°í™”
if 'current_question_idx' not in st.session_state:
    st.session_state.current_question_idx = 0
if 'interview_session_id' not in st.session_state:
    st.session_state.interview_session_id = None
if 'questions' not in st.session_state:
    st.session_state.questions = []

# ì–¼êµ´ ì¸ì‹ìš© Cascade (ì—†ì–´ë„ ë™ì‘í•˜ë„ë¡ ì˜ˆì™¸ì²˜ë¦¬)
face_cascade = None
try:
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
except:
    pass


# ==============================================================================
# 4. [ë©´ì ‘ ì‹œì‘ ì „] ì´ë ¥ì„œ ì„ íƒ ë° ì„¸ì…˜ ìƒì„± í™”ë©´
# ==============================================================================
if st.session_state.interview_session_id is None:
    st.subheader("ğŸ“Œ ë©´ì ‘ ì¤€ë¹„")
    
    # ---------------------------------------------------------
    # (1) ì´ë ¥ì„œ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° (ìºì‹± ì ìš©)
    # ---------------------------------------------------------
    @st.cache_data(show_spinner=False, ttl=60)
    def fetch_my_resumes(token):
        try:
            r = requests.get(f"{API_BASE}/api/v1/resume/", headers={"Authorization": f"Bearer {token}"}, timeout=5)
            if r.status_code == 200:
                return r.json()
            return []
        except:
            return []

    with st.spinner("ë‚´ ì´ë ¥ì„œ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        resumes_data = fetch_my_resumes(st.session_state['token'])
    
    # ë°ì´í„° ì •ê·œí™” (ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜)
    resumes = []
    if isinstance(resumes_data, list):
        resumes = resumes_data
    elif isinstance(resumes_data, dict):
        resumes = resumes_data.get("items") or resumes_data.get("data") or []

    # ---------------------------------------------------------
    # (2) ì´ë ¥ì„œ ì„ íƒ UI
    # ---------------------------------------------------------
    selected_resume_id = None
    
    if not resumes:
        st.warning("ë“±ë¡ëœ ì´ë ¥ì„œê°€ ì—†ìŠµë‹ˆë‹¤. 'ì˜¨ë³´ë”©' ë©”ë‰´ì—ì„œ ì´ë ¥ì„œë¥¼ ë¨¼ì € ë“±ë¡í•´ì£¼ì„¸ìš”.")
        if st.button("ì´ë ¥ì„œ ë“±ë¡í•˜ëŸ¬ ê°€ê¸°"):
            st.switch_page("pages/4_ğŸ‘¤_ì˜¨ë³´ë”©.py")
        st.stop()
    else:
        # ë³´ê¸° ì¢‹ì€ ë¼ë²¨ ìƒì„± í•¨ìˆ˜
        def get_resume_label(r):
            job = r.get("job_title", "ì§ë¬´ ë¯¸ìƒ")
            company = r.get("target_company", "ëª©í‘œ íšŒì‚¬ ë¯¸ìƒ")
            date = r.get("created_at", "")[:10]
            return f"[{date}] {job} ({company})"

        # IDì™€ ë¼ë²¨ ë§¤í•‘
        resume_options = {r["resume_id"]: get_resume_label(r) for r in resumes}
        
        # ì„ íƒ ë°•ìŠ¤
        selected_resume_id = st.selectbox(
            "ë©´ì ‘ì— ì‚¬ìš©í•  ì´ë ¥ì„œë¥¼ ì„ íƒí•˜ì„¸ìš”:",
            options=list(resume_options.keys()),
            format_func=lambda x: resume_options[x]
        )
        st.success(f"ì„ íƒëœ ì´ë ¥ì„œ: **{resume_options[selected_resume_id]}**")

    st.divider()

    # ---------------------------------------------------------
    # (3) ê°€ì´ë“œë¼ì¸ ë° ì¹´ë©”ë¼ í…ŒìŠ¤íŠ¸
    # ---------------------------------------------------------
    st.info("""
    **ë©´ì ‘ ê°€ì´ë“œë¼ì¸**
    1. ë°ì€ ì¡°ëª…ì„ ìœ ì§€í•˜ê³  ì–¼êµ´ì„ í™”ë©´ ì¤‘ì•™ì— ë§ì¶°ì£¼ì„¸ìš”.
    2. ì§ˆë¬¸ë‹¹ ë‹µë³€ ì‹œê°„ì€ 1ë¶„ ë‚´ì™¸ê°€ ì ë‹¹í•©ë‹ˆë‹¤.
    3. ì¤€ë¹„ê°€ ì™„ë£Œë˜ë©´ ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë©´ì ‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.
    """)

    # ì¹´ë©”ë¼ í…ŒìŠ¤íŠ¸ (ê³µê°„ ì°¨ì§€í•˜ë¯€ë¡œ ì ‘ì„ ìˆ˜ ìˆê²Œ)
    with st.expander("ğŸ“· ì¹´ë©”ë¼ í…ŒìŠ¤íŠ¸ ì—´ê¸°", expanded=False):
        components.html(
        """
        <style>
            #container {
                position: relative;
                width: 100%;
                max-width: 640px;
                margin: 0 auto;
            }
            video {
                width: 100%;
                height: auto;
                transform: scaleX(-1); /* ê±°ìš¸ ëª¨ë“œ */
                border-radius: 10px;
            }
            canvas {
                position: absolute;
                top: 0;
                left: 0;
                width: 100%;
                height: 100%;
                pointer-events: none;
                transform: scaleX(-1); /* ìº”ë²„ìŠ¤ë„ ê±°ìš¸ ëª¨ë“œ */
            }
            #status {
                position: absolute;
                bottom: 10px;
                left: 50%;
                transform: translateX(-50%);
                background: rgba(0,0,0,0.6);
                color: white;
                padding: 5px 10px;
                border-radius: 5px;
                font-family: sans-serif;
                font-size: 14px;
                display: none; /* JS ë¡œë”© ì „ì—” ìˆ¨ê¹€ */
            }
        </style>

        <div id="container">
            <video id="video" autoplay muted playsinline></video>
            <canvas id="overlay"></canvas>
            <div id="status">AI ëª¨ë¸ ë¡œë”© ì¤‘...</div>
        </div>

        <script type="module">
            import {
                FaceDetector,
                FilesetResolver
            } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/+esm";

            const video = document.getElementById("video");
            const canvas = document.getElementById("overlay");
            const ctx = canvas.getContext("2d");
            const statusDiv = document.getElementById("status");
            
            let faceDetector;
            let runningMode = "VIDEO";
            let lastVideoTime = -1;

            // 1. MediaPipe FaceDetector ì´ˆê¸°í™”
            async function initializeFaceDetector() {
                const vision = await FilesetResolver.forVisionTasks(
                    "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
                );
                
                faceDetector = await FaceDetector.createFromOptions(vision, {
                    baseOptions: {
                        modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite`,
                        delegate: "GPU"
                    },
                    runningMode: runningMode
                });
                
                statusDiv.style.display = "block";
                statusDiv.innerText = "ì¹´ë©”ë¼ ì¤€ë¹„ ì¤‘...";
                startCamera();
            }

            // 2. ì›¹ìº  ì‹œì‘
            function startCamera() {
                navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 } })
                .then(stream => {
                    video.srcObject = stream;
                    video.addEventListener("loadeddata", predictWebcam);
                    statusDiv.innerText = "ì–¼êµ´ì„ ì› ì•ˆì— ë§ì¶°ì£¼ì„¸ìš”.";
                })
                .catch(err => {
                    statusDiv.innerText = "ì¹´ë©”ë¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.";
                    console.error(err);
                });
            }

            // 3. ì‹¤ì‹œê°„ ê°ì§€ ë° ê·¸ë¦¬ê¸° ë£¨í”„
            async function predictWebcam() {
                // ìº”ë²„ìŠ¤ í¬ê¸°ë¥¼ ë¹„ë””ì˜¤ ì‹¤ì œ í¬ê¸°ì— ë§ì¶¤
                if (video.videoWidth > 0 && canvas.width !== video.videoWidth) {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                }

                let startTimeMs = performance.now();

                // ë¹„ë””ì˜¤ í”„ë ˆì„ì´ ë³€í–ˆì„ ë•Œë§Œ ê°ì§€ ìˆ˜í–‰
                if (video.currentTime !== lastVideoTime) {
                    lastVideoTime = video.currentTime;
                    
                    if (faceDetector) {
                        const detections = faceDetector.detectForVideo(video, startTimeMs).detections;
                        drawGuideAndFace(detections);
                    }
                }

                window.requestAnimationFrame(predictWebcam);
            }

            // 4. ê·¸ë¦¬ê¸° ë¡œì§ (ì› ê·¸ë¦¬ê¸° + íŒì •)
            function drawGuideAndFace(detections) {
                ctx.clearRect(0, 0, canvas.width, canvas.height);

                // ê°€ì´ë“œ ì› ì„¤ì •
                const centerX = canvas.width / 2;
                const centerY = canvas.height * 0.45; // í™”ë©´ ì•½ê°„ ìƒë‹¨
                const radius = canvas.width * 0.18;   // ì› í¬ê¸°

                let isInside = false;

                // ì–¼êµ´ì´ ê°ì§€ë˜ì—ˆëŠ”ì§€ í™•ì¸
                if (detections && detections.length > 0) {
                    const face = detections[0].boundingBox;
                    
                    // ì–¼êµ´ ì¤‘ì‹¬ì  ê³„ì‚°
                    const faceX = face.originX + (face.width / 2);
                    const faceY = face.originY + (face.height / 2);

                    // ì›ì˜ ì¤‘ì‹¬ê³¼ ì–¼êµ´ ì¤‘ì‹¬ ì‚¬ì´ì˜ ê±°ë¦¬ ê³„ì‚° (í”¼íƒ€ê³ ë¼ìŠ¤)
                    const distance = Math.sqrt(
                        Math.pow(faceX - centerX, 2) + Math.pow(faceY - centerY, 2)
                    );

                    // íŒì •: ê±°ë¦¬ê°€ í—ˆìš© ì˜¤ì°¨(ì˜ˆ: ë°˜ì§€ë¦„ì˜ 40%) ì´ë‚´ì¸ì§€
                    // ì¦‰, ì–¼êµ´ì´ ì›ì˜ ì¤‘ì‹¬ì— ê°€ê¹ê²Œ ë“¤ì–´ì™”ëŠ”ì§€ í™•ì¸
                    if (distance < radius * 0.5) {
                        isInside = true;
                    }
                }

                // ìƒ‰ìƒ ê²°ì • (ì•ˆì— ìˆìœ¼ë©´ ì´ˆë¡, ì•„ë‹ˆë©´ ë¹¨ê°•)
                const color = isInside ? "#00FF00" : "#FF0000"; // Lime Green or Red
                const lineWidth = isInside ? 6 : 4;

                // ì› ê·¸ë¦¬ê¸°
                ctx.beginPath();
                ctx.arc(centerX, centerY, radius, 0, 2 * Math.PI);
                ctx.lineWidth = lineWidth;
                ctx.strokeStyle = color;
                ctx.stroke();
                
                // (ì„ íƒì‚¬í•­) ìƒíƒœ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
                if (isInside) {
                    statusDiv.innerText = "ìœ„ì¹˜ê°€ ì ì ˆí•©ë‹ˆë‹¤! âœ…";
                    statusDiv.style.color = "#00FF00";
                } else {
                    statusDiv.innerText = "ì–¼êµ´ì„ ì› ì•ˆìœ¼ë¡œ ì´ë™í•´ì£¼ì„¸ìš” ğŸŸ¥";
                    statusDiv.style.color = "#FFcccc";
                }
            }

            // ì‹œì‘
            initializeFaceDetector();
        </script>
        """,
        height=550 # ë¹„ë””ì˜¤ ë¹„ìœ¨ì— ë§ì¶° ë„‰ë„‰í•˜ê²Œ
        )

    # ---------------------------------------------------------
    # (4) ë©´ì ‘ ì‹œì‘ ë²„íŠ¼
    # ---------------------------------------------------------
    if st.button("ğŸš€ ì¤€ë¹„ ì™„ë£Œ - ë©´ì ‘ ì‹œì‘", type="primary", use_container_width=True):
        if not selected_resume_id:
            st.error("ì´ë ¥ì„œë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
        else:
            with st.status("ë©´ì ‘ ì„¸ì…˜ì„ ìƒì„±í•˜ê³  ì§ˆë¬¸ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤...", expanded=True) as status:
                try:
                    # 1. ì„¸ì…˜ ìƒì„± (ì´ë ¥ì„œ ID í¬í•¨)
                    payload = {"resume_id": int(selected_resume_id)}
                    
                    res = requests.post(f"{API_BASE}/api/v1/session/", json=payload, headers=headers)
                    
                    if res.status_code in (200, 201):
                        sess_data = res.json()
                        session_id = sess_data['session_id']
                        st.session_state.interview_session_id = session_id
                        status.write("âœ… ì„¸ì…˜ ìƒì„± ì™„ë£Œ!")
                        
                        # 2. ì§ˆë¬¸ ëª©ë¡ ì¡°íšŒ (ìƒì„±ëœ ì„¸ì…˜ IDë¡œ ì¡°íšŒ)
                        q_res = requests.get(f"{API_BASE}/api/v1/question/session/{session_id}", headers=headers)
                        
                        if q_res.status_code == 200:
                            questions = q_res.json()
                            if questions:
                                st.session_state.questions = questions
                                st.session_state.current_question_idx = 0
                                status.update(label="âœ… ì¤€ë¹„ ì™„ë£Œ! ë©´ì ‘ í™”ë©´ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.", state="complete")
                                time.sleep(1)
                                st.rerun()
                            else:
                                status.update(label="âš ï¸ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨", state="error")
                                st.error("ìƒì„±ëœ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            status.update(label="âš ï¸ ì§ˆë¬¸ ì¡°íšŒ ì‹¤íŒ¨", state="error")
                            st.error(f"ì§ˆë¬¸ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {q_res.status_code}")
                    else:
                        status.update(label="âŒ ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨", state="error")
                        st.error(f"ì˜¤ë¥˜: {res.text}")
                        
                except Exception as e:
                    status.update(label="âš ï¸ ì‹œìŠ¤í…œ ì˜¤ë¥˜", state="error")
                    st.error(f"ì ‘ì† ì˜¤ë¥˜: {e}")

    st.stop() # ë©´ì ‘ ì‹œì‘ ì „ì—ëŠ” ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ

# ==============================================================================
# 5. [ë©´ì ‘ ì§„í–‰] ì§ˆë¬¸ í‘œì‹œ, AI ë©´ì ‘ê´€(TTS), ë‹µë³€ ë…¹í™”
# ==============================================================================
questions = st.session_state.questions
idx = st.session_state.current_question_idx

if idx < len(questions):
    current_q = questions[idx]
    
    # ---------------------------------------------------------
    # ğŸ¯ í™”ë©´ ìƒë‹¨: ì§„í–‰ë¥  ë° ì§ˆë¬¸ ì •ë³´
    # ---------------------------------------------------------
    progress = (idx) / len(questions)
    st.progress(progress, text=f"ì§„í–‰ë¥  {idx + 1}/{len(questions)}")
    
    st.divider()

    # ---------------------------------------------------------
    # ğŸ¯ í™”ë©´ 2ë¶„í•  (ì™¼ìª½: AI ë©´ì ‘ê´€ / ì˜¤ë¥¸ìª½: ë‚´ ëª¨ìŠµ)
    # ---------------------------------------------------------
    # (2) ì§ˆë¬¸ í…ìŠ¤íŠ¸ í‘œì‹œ
    st.info(f"ğŸ—£ï¸ **Q{idx+1}.** {current_q['content']}")
    st.caption(f"ìœ í˜•: {current_q['category']}")
    col_ai, col_user = st.columns([1, 1], gap="medium")

    # ==========================
    # [ì™¼ìª½] AI ë©´ì ‘ê´€ ì˜ì—­
    # ==========================
    with col_ai:
        st.markdown("### ğŸ‘©â€ğŸ’¼ AI ë©´ì ‘ê´€")
        
        # âœ… 7_ë©´ì ‘ ì§„í–‰.py (with col_ai ë¸”ë¡ ì•ˆ) : TTS -> Wav2Lip(lipsync) -> video ì¬ìƒ
        # - interviewer_img(URL) ê·¸ëŒ€ë¡œ ë°±ì—”ë“œì— ì „ë‹¬
        # - ì§ˆë¬¸ë³„ë¡œ mp3/mp4ë¥¼ session_stateì— ìºì‹œí•´ì„œ ì¤‘ë³µ ìƒì„± ë°©ì§€

        # (1) ë©´ì ‘ê´€ ì´ë¯¸ì§€ (ì´ë¯¸ ë„ˆ ì½”ë“œì— ìˆë˜ ê±°)
        interviewer_img = "https://images.unsplash.com/photo-1500648767791-00dcc994a43e?w=500&auto=format&fit=crop&q=60&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxzZWFyY2h8M3x8JUVDJTk2JUJDJUVBJUI1JUI0fGVufDB8fDB8fHww"
        # st.image(interviewer_img, caption="AI ë©´ì ‘ê´€", use_container_width=True)



        # (3) TTS ìƒì„±(ì´ë¯¸ ìˆë˜ ë¡œì§ ìœ ì§€) + ìºì‹œ í‚¤
        tts_key = f"tts_audio_{current_q['question_id']}"
        if tts_key not in st.session_state:
            with st.spinner("ë©´ì ‘ê´€ì´ ì§ˆë¬¸ì„ ì½ì–´ì£¼ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    tts_res = requests.post(
                        f"{API_BASE}/api/v1/interview/tts",
                        headers=headers,
                        json={"text": current_q["content"], "voice": "nova"},
                        timeout=30,
                    )
                    if tts_res.status_code == 200:
                        st.session_state[tts_key] = tts_res.content  # mp3 bytes
                    else:
                        st.warning(f"TTS ì‹¤íŒ¨: {tts_res.status_code} {tts_res.text[:200]}")
                except Exception as e:
                    st.warning(f"TTS Error: {e}")

        # (4) âœ… Wav2Lip(mp4) ìƒì„± + ìºì‹œ
        lipsync_key = f"lipsync_mp4_{current_q['question_id']}"
        if tts_key in st.session_state and lipsync_key not in st.session_state:
            with st.spinner("ë©´ì ‘ê´€ ë¦½ì‹±í¬ ì˜ìƒì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    files = {
                        "audio": ("tts.mp3", st.session_state[tts_key], "audio/mpeg")
                    }
                    data = {
                        "avatar_url": interviewer_img,  # âœ… ì—¬ê¸°!
                        "resize_factor": "1",
                        "nosmooth": "false",
                    }

                    ls_res = requests.post(
                        f"{API_BASE}/api/v1/interview/lipsync",
                        headers=headers,
                        files=files,
                        data=data,
                        timeout=180,
                    )

                    if ls_res.status_code == 200:
                        st.session_state[lipsync_key] = ls_res.content  # mp4 bytes
                    else:
                        st.warning(f"ë¦½ì‹±í¬ ì‹¤íŒ¨: {ls_res.status_code} {ls_res.text[:300]}")
                except Exception as e:
                    st.warning(f"ë¦½ì‹±í¬ Error: {e}")

        # (5) âœ… mp4 ìˆìœ¼ë©´ ì˜ìƒ ì¬ìƒ, ì—†ìœ¼ë©´ ì˜¤ë””ì˜¤ fallback
        if lipsync_key in st.session_state:
            st.video(st.session_state[lipsync_key], format="video/mp4", autoplay=True)
        elif tts_key in st.session_state:
            st.audio(st.session_state[tts_key], format="audio/mp3", autoplay=True)
        else:
            st.warning("ì˜¤ë””ì˜¤/ì˜ìƒ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    # ==========================
    # [ì˜¤ë¥¸ìª½] ì§€ì›ì(ë‚˜) ë…¹í™” ì˜ì—­
    # ==========================
    with col_user:
        st.markdown("### ğŸ™ï¸ ë‹µë³€ ë…¹í™”")

        if "recorded_video" not in st.session_state:
            st.session_state.recorded_video = None

        # ì»¤ìŠ¤í…€ JS ë…¹í™” ì»´í¬ë„ŒíŠ¸
        video_base64 = components.html(
        """
        <style>
        body { margin: 0; padding: 0; overflow: hidden; }
        #video-wrapper {
            position: relative;
            width: 100%;
            aspect-ratio: {ASPECT_W}/{ASPECT_H};
            background: #000;
            border-radius: 12px;
            overflow: hidden;
        }
        video {
            width: 100%;
            height: 100%;             /* âœ… wrapper ë†’ì´ë¥¼ ê½‰ ì±„ì›€ */
            height: auto;
            object-fit: cover;        /* âœ… ë¹„ìœ¨ ë§ì¶”ë©´ì„œ í¬ë¡­ */
            transform: scaleX(-1); /* ê±°ìš¸ ëª¨ë“œ */
        }
        #controls {
            margin-top: 10px;
            display: flex;
            justify-content: center;
            gap: 10px;
        }
        button {
            font-size: 14px;
            padding: 8px 16px;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-weight: bold;
            color: white;
        }
        #startBtn { background-color: #28a745; }
        #startBtn:disabled { background-color: #ccc; cursor: not-allowed; }
        #stopBtn { background-color: #dc3545; }
        #stopBtn:disabled { background-color: #ccc; cursor: not-allowed; }
        
        .timer-box {
            text-align: center;
            font-size: 18px;
            font-family: monospace;
            margin-top: 5px;
            color: #333;
        }
        #warning { color: red; font-weight: bold; font-size: 14px; height: 20px; text-align: center; }
        </style>

        <div id="video-wrapper">
            <video id="preview" autoplay muted playsinline></video>
        </div>

        <div class="timer-box">
            â± <span id="timer">00:00</span> / 02:00
        </div>
        <div id="warning"></div>

        <div id="controls">
            <button id="startBtn" onclick="startRecording()">â–¶ ë…¹í™” ì‹œì‘</button>
            <button id="stopBtn" onclick="stopRecording()" disabled>â–  ë…¹í™” ì¢…ë£Œ</button>
        </div>

        <script>
        let mediaRecorder;
        let recordedChunks = [];
        let timerInterval;
        let elapsed = 0;
        let stream;

        const MAX_TIME = 120;
        const WARNING_TIME = 105;

        // ì¹´ë©”ë¼ ê¶Œí•œ ìš”ì²­ ë° ë¯¸ë¦¬ë³´ê¸° ì‹œì‘
        navigator.mediaDevices.getUserMedia({ video: true, audio: true })
        .then(s => {
            stream = s;
            document.getElementById("preview").srcObject = stream;
        })
        .catch(err => {
            document.getElementById("warning").innerText = "ì¹´ë©”ë¼/ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.";
        });

        function formatTime(sec) {
            const m = String(Math.floor(sec / 60)).padStart(2, "0");
            const s = String(sec % 60).padStart(2, "0");
            return `${m}:${s}`;
        }

        function startRecording() {
            if (!stream) return;
            
            document.getElementById("startBtn").disabled = true;
            document.getElementById("stopBtn").disabled = false;

            elapsed = 0;
            recordedChunks = [];
            document.getElementById("timer").innerText = "00:00";
            document.getElementById("warning").innerText = "";

            mediaRecorder = new MediaRecorder(stream, { mimeType: 'video/webm' });

            mediaRecorder.ondataavailable = e => {
                if (e.data.size > 0) recordedChunks.push(e.data);
            };

            mediaRecorder.start();

            timerInterval = setInterval(() => {
                elapsed++;
                document.getElementById("timer").innerText = formatTime(elapsed);

                if (elapsed === WARNING_TIME) {
                    document.getElementById("warning").innerText = "âš ï¸ 15ì´ˆ ë‚¨ì•˜ìŠµë‹ˆë‹¤!";
                }

                if (elapsed >= MAX_TIME) {
                    stopRecording();
                }
            }, 1000);
        }

        function stopRecording() {
            document.getElementById("stopBtn").disabled = true;

            if (!mediaRecorder || mediaRecorder.state === "inactive") return;

            clearInterval(timerInterval);
            mediaRecorder.stop();

            mediaRecorder.onstop = () => {
                document.getElementById("startBtn").disabled = false;

                const blob = new Blob(recordedChunks, { type: "video/webm" });
                const reader = new FileReader();

                reader.onloadend = () => {
                    // base64 ë¬¸ìì—´ë§Œ ì¶”ì¶œí•˜ì—¬ Streamlitìœ¼ë¡œ ì „ì†¡
                    const base64data = reader.result.split(",")[1];
                    window.parent.postMessage({
                        type: "streamlit:setComponentValue",
                        value: base64data
                    }, "*");
                };

                reader.readAsDataURL(blob);
            };
        }
        </script>
        """,
        height=700, # ë†’ì´ ì¡°ì • (ë„ˆë¬´ í¬ë©´ ë ˆì´ì•„ì›ƒ ê¹¨ì§)
        scrolling=False
        )

        # JSì—ì„œ ê°’ì´ ë„˜ì–´ì˜¤ë©´ ì„¸ì…˜ì— ì €ì¥
        if video_base64:
            st.session_state.recorded_video = video_base64
            st.success("âœ… ë…¹í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì œì¶œí•˜ì„¸ìš”.")


    # ==========================
    # [í•˜ë‹¨] ì œì¶œ ë° ì´ë™ ë²„íŠ¼
    # ==========================
    # ë…¹í™”ëœ ì˜ìƒì´ ìˆì„ ë•Œë§Œ ë²„íŠ¼ í™œì„±í™”
    if st.session_state.get("recorded_video"):
        st.divider()
        
        # [A] ì¤‘ê°„ ì§ˆë¬¸ (1~4ë²ˆ) -> "ë‹¤ìŒ ì§ˆë¬¸" ë²„íŠ¼
        if idx < 4:  # 0,1,2,3 (ì´ 4ê°œ) -> idx < 4 ì´ë©´ 5ë²ˆì§¸(idx=4) ì§ˆë¬¸ì´ ë‚¨ìŒ
            if st.button("â¡ ì œì¶œí•˜ê³  ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ì´ë™", type="primary", use_container_width=True):
                with st.spinner("ë‹µë³€ì„ ì—…ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        video_bytes = base64.b64decode(st.session_state.recorded_video)
                        files = {"file": ("answer.webm", video_bytes, "video/webm")}
                        data = {"question_id": str(current_q["question_id"])}

                        res = requests.post(
                            f"{API_BASE}/api/v1/interview/upload",
                            headers=headers,
                            files=files,
                            data=data
                        )

                        if res.status_code in (200, 201):
                            # ì„±ê³µ ì‹œ ìƒíƒœ ì´ˆê¸°í™” í›„ ì´ë™
                            st.session_state.recorded_video = None
                            st.session_state.current_question_idx += 1
                            st.toast("ë‹µë³€ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.", icon="ğŸ’¾")
                            time.sleep(0.5)
                            st.rerun()
                        else:
                            st.error(f"ì—…ë¡œë“œ ì‹¤íŒ¨: {res.text}")
                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

        # [B] ë§ˆì§€ë§‰ ì§ˆë¬¸ (5ë²ˆ) -> "ì¢…ë£Œ ë° ë¶„ì„" ë²„íŠ¼
        else:
            if st.button("ğŸ ë©´ì ‘ ì¢…ë£Œ ë° ê²°ê³¼ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
                with st.status("ë§ˆì§€ë§‰ ë‹µë³€ì„ ì €ì¥í•˜ê³  ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...", expanded=True) as status:
                    try:
                        # 1. ë§ˆì§€ë§‰ ì˜ìƒ ì—…ë¡œë“œ
                        video_bytes = base64.b64decode(st.session_state.recorded_video)
                        files = {"file": ("answer.webm", video_bytes, "video/webm")}
                        data = {"question_id": str(current_q["question_id"])}

                        res = requests.post(
                            f"{API_BASE}/api/v1/interview/upload",
                            headers=headers,
                            files=files,
                            data=data
                        )
                        
                        if res.status_code not in (200, 201):
                            status.update(label="âŒ ë§ˆì§€ë§‰ ì˜ìƒ ì—…ë¡œë“œ ì‹¤íŒ¨", state="error")
                            st.error(res.text)
                            st.stop()
                        
                        status.write("âœ… ë‹µë³€ ì €ì¥ ì™„ë£Œ")

                        # 2. ë¶„ì„ ìš”ì²­ (ì„¸ì…˜ ë‹¨ìœ„)
                        # ì„¸ì…˜ IDê°€ í•„ìš”í•˜ë¯€ë¡œ session_stateë‚˜ current_qì—ì„œ ê°€ì ¸ì˜´
                        session_id = st.session_state.interview_session_id
                        
                        analyze_res = requests.post(
                            f"{API_BASE}/api/v1/analysis/session/{session_id}",
                            headers=headers,
                            timeout=10 # íŠ¸ë¦¬ê±°ë§Œ í•˜ë¯€ë¡œ ì§§ê²Œ
                        )
                        
                        if analyze_res.status_code == 200:
                            status.update(label="ğŸš€ ë¶„ì„ ì‹œì‘ë¨!", state="complete")
                            time.sleep(1)
                            st.switch_page("pages/6_ğŸ“Š_ë¦¬í¬íŠ¸.py")
                        else:
                            status.update(label="âš ï¸ ë¶„ì„ ìš”ì²­ ì‹¤íŒ¨", state="error")
                            st.error(analyze_res.text)
                            
                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜: {e}")


else:
    # -----------------------------
    # 6. ëª¨ë“  ì§ˆë¬¸ ì¢…ë£Œ ì‹œ
    # -----------------------------
    st.balloons()
    st.success("ğŸ‰ ëª¨ë“  ë©´ì ‘ ì§ˆë¬¸ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    st.markdown("### ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!")
    st.info("AIê°€ ì „ì²´ ë©´ì ‘ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì¢…í•© ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    
    if st.button("ğŸ“Š ê²°ê³¼ ë¦¬í¬íŠ¸ í™•ì¸í•˜ê¸°", type="primary", use_container_width=True):
        # (ì„ íƒ) ì—¬ê¸°ì„œ ì„¸ì…˜ ì „ì²´ ë¶„ì„ íŠ¸ë¦¬ê±° APIë¥¼ í˜¸ì¶œí•  ìˆ˜ë„ ìˆìŒ
        # requests.post(f"{API_BASE}/api/v1/analysis/session/{st.session_state.interview_session_id}", headers=headers)
        st.switch_page("pages/6_ğŸ“Š_ë¦¬í¬íŠ¸.py")