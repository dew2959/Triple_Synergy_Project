import cv2
import numpy as np
import mediapipe as mp
import time
import os
import math
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

# =========================================================
# âš™ï¸ ì„¤ì • ë° ìƒìˆ˜ ì •ì˜
# =========================================================
MODULE_NAME = "visual_tuner_final"
# ëª¨ë¸ ê²½ë¡œ (ë³¸ì¸ì˜ í”„ë¡œì íŠ¸ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
MODEL_PATH = os.path.join("app", "engines", "visual", "models", "face_landmarker.task")

# 1. ìì„¸ (Posture)
NOSE_LANDMARK_IDX = 1       # ì½” ë
HEAD_TOP_LANDMARK_IDX = 10  # ì •ìˆ˜ë¦¬
NOSE_CENTER_RANGE = (0.40, 0.60) # ì¤‘ì•™ ì¸ì • ë²”ìœ„
STD_REF_ANGLE = 5.0         # ê³ ê°œ ê¸°ìš¸ì„ í—ˆìš© í‘œì¤€í¸ì°¨

# 2. í‘œì • (Expression)
SMILE_THRESHOLD = 0.5       # ë¯¸ì†Œ ê¸°ì¤€ê°’

# 3. ê¸´ì¥ë„ (Blink)
BLINK_THRESHOLD = 0.5       # ëˆˆ ê°ìŒ ê¸°ì¤€ê°’

# 4. ì‹œì„  (Gaze)
# ì™¼ìª½ ëˆˆ
LEFT_EYE_INNER = 362
LEFT_EYE_OUTER = 263
LEFT_IRIS_CENTER = 468
# ì˜¤ë¥¸ìª½ ëˆˆ
RIGHT_EYE_INNER = 33
RIGHT_EYE_OUTER = 133
RIGHT_IRIS_CENTER = 473
GAZE_THRESHOLD = 0.8  # ì‹œì„  ì´íƒˆ ê¸°ì¤€ (0.0~1.0, 0.6 ì´ìƒì´ë©´ ì´íƒˆë¡œ ê°„ì£¼)


# =========================================================
# ğŸ› ï¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =========================================================
def draw_text(img, text, x, y, color=(0, 255, 0), font_scale=0.6, thickness=2):
    cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), thickness+1)
    cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)

def draw_bar(img, x, y, w, h, val, max_val=1.0, color=(0, 255, 255), label=""):
    """ê²Œì´ì§€ ë°” ê·¸ë¦¬ê¸°"""
    cv2.rectangle(img, (x, y), (x+w, y+h), (50, 50, 50), -1)
    ratio = max(0.0, min(1.0, val / max_val))
    fill_w = int(w * ratio)
    cv2.rectangle(img, (x, y), (x+fill_w, y+h), color, -1)
    cv2.rectangle(img, (x, y), (x+w, y+h), (200, 200, 200), 1)
    cv2.putText(img, f"{label}", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)

def calculate_angle(p1, p2):
    """ì •ìˆ˜ë¦¬ì™€ ì½”ë¥¼ ì‡ëŠ” ì„ ì˜ ê°ë„ ê³„ì‚° (Roll)"""
    dx = p1.x - p2.x
    dy = p1.y - p2.y
    return math.degrees(math.atan2(dy, dx)) + 90

def get_eye_gaze_score(face, inner_idx, outer_idx, iris_idx):
    """í•œìª½ ëˆˆì˜ ì‹œì„  ì´íƒˆ ì ìˆ˜ ê³„ì‚°"""
    p_inner = face[inner_idx]
    p_outer = face[outer_idx]
    p_iris = face[iris_idx]
    
    eye_width = abs(p_inner.x - p_outer.x)
    if eye_width == 0: return 0.0
    
    eye_center = (p_inner.x + p_outer.x) / 2.0
    dist_from_center = abs(p_iris.x - eye_center)
    
    # ì •ê·œí™”: (ê±°ë¦¬ / ëˆˆë™ìë°˜ê²½) ëŠë‚Œìœ¼ë¡œ ë³€í™˜. 
    # ë³´í†µ ëˆˆê¸¸ì´ì˜ ì ˆë°˜(0.5)ì„ ë„˜ì–´ê°€ë©´ ì™„ì „ í°ììœ„
    # ë³´ì •ê³„ìˆ˜ 2.5ë¥¼ ê³±í•´ 0~1 ì‚¬ì´ ìŠ¤ì½”ì–´ë¡œ ë§Œë“¦
    score = (dist_from_center / (eye_width / 2.0)) * 2.5
    return score

# =========================================================
# ğŸš€ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# =========================================================
def main():
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
        return

    # ëª¨ë¸ ë¡œë“œ
    base_options = python.BaseOptions(model_asset_path=MODEL_PATH)
    options = vision.FaceLandmarkerOptions(
        base_options=base_options,
        running_mode=vision.RunningMode.VIDEO,
        num_faces=1,
        output_face_blendshapes=True # í‘œì •/ê¹œë¹¡ì„ í•„ìˆ˜
    )
    landmarker = vision.FaceLandmarker.create_from_options(options)

    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("âœ… ì¢…í•© ë¹„ì£¼ì–¼ íŠœë„ˆ ì‹œì‘! (ì¢…ë£Œ: q)")

    # ë°ì´í„° ì €ì¥ì†Œ
    history_angles = []
    blink_count = 0
    prev_eye_closed = False
    start_time = time.time()
    
    # ì‹œê° íš¨ê³¼ìš©
    blink_feedback_timer = 0

    while True:
        ret, frame = cap.read()
        if not ret: break

        # 1. ì „ì²˜ë¦¬ (ì¢Œìš°ë°˜ì „)
        frame = cv2.flip(frame, 1)
        h, w, _ = frame.shape
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        timestamp_ms = int((time.time() - start_time) * 1000)
        
        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb)
        result = landmarker.detect_for_video(mp_image, timestamp_ms)

        # ì´ˆê¸°ê°’
        is_face = False
        nose_x_ratio = 0.5
        roll_angle = 0.0
        smile_score = 0.0
        blink_score = 0.0
        gaze_score = 0.0

        # =================================================
        # ğŸ§  ë¶„ì„ ë¡œì§
        # =================================================
        if result.face_landmarks:
            is_face = True
            face = result.face_landmarks[0]
            
            # --- [1] ìì„¸ (Posture) ---
            nose = face[NOSE_LANDMARK_IDX]
            head = face[HEAD_TOP_LANDMARK_IDX]
            nose_x_ratio = nose.x
            
            # ê¸°ìš¸ê¸° ê³„ì‚°
            roll_angle = calculate_angle(head, nose)
            history_angles.append(roll_angle)
            if len(history_angles) > 30: history_angles.pop(0) # ìµœê·¼ 30í”„ë ˆì„ë§Œ ìœ ì§€
            angle_std = np.std(history_angles) if len(history_angles) > 1 else 0.0

            # --- [2] í‘œì • & ê¹œë¹¡ì„ (Blendshapes) ---
            if result.face_blendshapes:
                bs = result.face_blendshapes[0]
                
                # ë¯¸ì†Œ
                s_l = next((x.score for x in bs if x.category_name=='mouthSmileLeft'), 0.0)
                s_r = next((x.score for x in bs if x.category_name=='mouthSmileRight'), 0.0)
                smile_score = (s_l + s_r) / 2.0
                
                # ê¹œë¹¡ì„
                b_l = next((x.score for x in bs if x.category_name=='eyeBlinkLeft'), 0.0)
                b_r = next((x.score for x in bs if x.category_name=='eyeBlinkRight'), 0.0)
                blink_score = (b_l + b_r) / 2.0
                
                is_closed = blink_score > BLINK_THRESHOLD
                if is_closed and not prev_eye_closed:
                    blink_count += 1
                    blink_feedback_timer = 5 # 5í”„ë ˆì„ê°„ ê°•ì¡°
                prev_eye_closed = is_closed

            # --- [3] ì‹œì„  (Gaze) ---
            g_left = get_eye_gaze_score(face, LEFT_EYE_INNER, LEFT_EYE_OUTER, LEFT_IRIS_CENTER)
            g_right = get_eye_gaze_score(face, RIGHT_EYE_INNER, RIGHT_EYE_OUTER, RIGHT_IRIS_CENTER)
            gaze_score = (g_left + g_right) / 2.0


            # =================================================
            # ğŸ¨ í™”ë©´ ê·¸ë¦¬ê¸° (Visual Debugging)
            # =================================================
            
            # 1. ì¤‘ì•™ ê°€ì´ë“œ ë°•ìŠ¤
            box_color = (0, 255, 0) # Green
            if not (NOSE_CENTER_RANGE[0] <= nose_x_ratio <= NOSE_CENTER_RANGE[1]):
                box_color = (0, 0, 255) # Red (ì´íƒˆ)
            
            x1, x2 = int(w*NOSE_CENTER_RANGE[0]), int(w*NOSE_CENTER_RANGE[1])
            cv2.rectangle(frame, (x1, 0), (x2, h), box_color, 1)
            
            # 2. ì–¼êµ´ ì¶• (ê¸°ìš¸ê¸°)
            pn = (int(nose.x*w), int(nose.y*h))
            ph = (int(head.x*w), int(head.y*h))
            line_col = (0, 255, 255) if abs(roll_angle) < 10 else (0, 0, 255)
            cv2.line(frame, pn, ph, line_col, 2)
            cv2.circle(frame, pn, 5, (0, 0, 255), -1)

            # 3. ëˆˆë™ì (ì‹œì„ )
            # ì™¼ìª½ ëˆˆ ì‹œê°í™”
            pil = (int(face[LEFT_IRIS_CENTER].x * w), int(face[LEFT_IRIS_CENTER].y * h))
            pir = (int(face[RIGHT_IRIS_CENTER].x * w), int(face[RIGHT_IRIS_CENTER].y * h))
            
            gaze_col = (0, 255, 0)
            if gaze_score > GAZE_THRESHOLD: gaze_col = (0, 0, 255) # ì‹œì„  ì´íƒˆì‹œ ë¹¨ê°•
            
            cv2.circle(frame, pil, 3, gaze_col, -1)
            cv2.circle(frame, pir, 3, gaze_col, -1)
            
            # ì‹œì„  ì¤‘ì•™ ê°€ì´ë“œë¼ì¸ (ëˆˆë†’ì´)
            cv2.line(frame, (pil[0]-20, pil[1]), (pil[0]+20, pil[1]), (100,100,100), 1)
            cv2.line(frame, (pir[0]-20, pir[1]), (pir[0]+20, pir[1]), (100,100,100), 1)

        # =================================================
        # ğŸ“º ëŒ€ì‹œë³´ë“œ (Dashboard) UI
        # =================================================
        # íŒ¨ë„ ë°°ê²½
        panel_w = 280
        cv2.rectangle(frame, (10, 10), (10+panel_w, 360), (0, 0, 0), -1)
        cv2.rectangle(frame, (10, 10), (10+panel_w, 360), (255, 255, 255), 1)
        
        y_cursor = 40
        gap = 30
        
        # [Header]
        status = "DETECTED" if is_face else "SEARCHING..."
        draw_text(frame, f"STATUS: {status}", 20, y_cursor, (0, 255, 0) if is_face else (0, 0, 255))
        y_cursor += 40

        # 1. ìì„¸ (Position)
        pos_txt = "CENTER" if (NOSE_CENTER_RANGE[0] <= nose_x_ratio <= NOSE_CENTER_RANGE[1]) else "OFF-CENTER"
        col = (0, 255, 0) if pos_txt == "CENTER" else (0, 0, 255)
        draw_text(frame, f"1. Position: {pos_txt}", 20, y_cursor, col)
        y_cursor += gap
        
        # 2. ê¸°ìš¸ê¸° (Roll)
        roll_txt = f"{roll_angle:.1f} deg"
        col = (0, 255, 0) if abs(roll_angle) < 10 else (0, 0, 255)
        draw_text(frame, f"2. Head Roll: {roll_txt}", 20, y_cursor, col)
        draw_bar(frame, 180, y_cursor-15, 80, 10, abs(roll_angle), 20.0, col)
        y_cursor += gap
        
        # 3. ì›€ì§ì„ (Stability)
        std_txt = f"Stable ({angle_std:.1f})" if angle_std < STD_REF_ANGLE else f"Shaky ({angle_std:.1f})"
        col = (0, 255, 0) if angle_std < STD_REF_ANGLE else (0, 0, 255)
        draw_text(frame, f"3. Stability: {std_txt}", 20, y_cursor, col)
        y_cursor += gap + 10

        # 4. ì‹œì„  (Gaze)
        print(gaze_score)
        gaze_state = "GOOD" if gaze_score < GAZE_THRESHOLD else "BAD"
        col = (0, 255, 0) if gaze_state == "GOOD" else (0, 0, 255)
        draw_text(frame, f"4. Eye Contact: {gaze_state}", 20, y_cursor, col)
        draw_bar(frame, 180, y_cursor-15, 80, 10, gaze_score, 1.0, col)
        y_cursor += gap

        # 5. ë¯¸ì†Œ (Smile)
        smile_state = "Smiling" if smile_score > SMILE_THRESHOLD else "Neutral"
        col = (255, 255, 0) if smile_score > SMILE_THRESHOLD else (200, 200, 200)
        draw_text(frame, f"5. Smile: {smile_state}", 20, y_cursor, col)
        draw_bar(frame, 180, y_cursor-15, 80, 10, smile_score, 1.0, col)
        y_cursor += gap

        # 6. ê¹œë¹¡ì„ (Blink)
        bpm = (blink_count / ((time.time()-start_time)/60)) if (time.time()-start_time) > 1 else 0
        blink_col = (0, 255, 255) if blink_feedback_timer > 0 else (200, 200, 200)
        draw_text(frame, f"6. Blinks: {blink_count} ({bpm:.0f}/m)", 20, y_cursor, blink_col)
        
        if blink_feedback_timer > 0:
            blink_feedback_timer -= 1
            cv2.circle(frame, (260, y_cursor-5), 8, (0, 255, 255), -1)

        cv2.imshow('Final Visual Tuner', frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
    landmarker.close()

if __name__ == "__main__":
    main()