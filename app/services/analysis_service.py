import traceback
import json  # ğŸ‘ˆ [í•„ìˆ˜] ì´ê±° ê¼­ ì¶”ê°€í•´ì£¼ì„¸ìš”!
from psycopg2.extensions import connection
from app.utils.media_utils import MediaUtils

# Engines
from app.engines.visual.engine import run_visual
from app.engines.voice.engine import run_voice
from app.engines.stt.engine import run_stt
from app.engines.llm.engine import run_content

# Repositories
from app.repositories.answer_repo import answer_repo
from app.repositories.visual_repo import visual_repo
from app.repositories.voice_repo import voice_repo
from app.repositories.content_repo import content_repo

# Schemas
from app.schemas.visual import VisualDBPayload
from app.schemas.voice import VoiceDBPayload
from app.schemas.content import ContentDBPayload

# âœ… [ì¶”ê°€] Final Report Service
from app.services.final_report_service import FinalReportService

from app.utils.report_llm_client import ReportLLMClient



class AnalysisService:
    def run_full_analysis(self, conn: connection, answer_id: int, file_path: str):
        print(f"ğŸ¬ [Analysis Start] Answer ID: {answer_id}")

        # 1. ë‹µë³€ ì¡°íšŒ
        answer = answer_repo.get_by_id(conn, answer_id)
        if not answer:
            print("âŒ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # âœ… [ì¶”ê°€] session_id í™•ë³´ (í‚¤ ì´ë¦„ì´ ë‹¤ë¥´ë©´ ìˆ˜ì •)
        session_id = answer.get("session_id")
        if not session_id:
            print("âŒ session_idê°€ ì—†ì–´ final reportë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (answerì— session_idê°€ í•„ìš”)")
            # ì—¬ê¸°ì„œ return í• ì§€, ê·¸ëƒ¥ final reportë§Œ ìŠ¤í‚µí• ì§€ ì„ íƒ ê°€ëŠ¥
            # ì§€ê¸ˆì€ final reportë§Œ ìŠ¤í‚µí•˜ê³  ë¶„ì„ì€ ê³„ì† ì§„í–‰í•˜ë„ë¡ ë‘ 

        # 2. ìƒíƒœ ë³€ê²½
        print(f"ğŸ”„ ìƒíƒœ ë³€ê²½: PENDING -> PROCESSING")
        answer_repo.update_analysis_status(conn, answer_id, "PROCESSING")

        try:
            # 0. ì˜¤ë””ì˜¤ ì¶”ì¶œ
            print("ğŸ”Š ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘...")
            audio_path = MediaUtils.extract_audio(file_path)

            # =================================================
            # 1. ë¹„ì£¼ì–¼ ë¶„ì„
            # =================================================
            print(f"ğŸ‘ï¸ ë¹„ì£¼ì–¼ ë¶„ì„ ì‹œì‘...")
            visual_output = run_visual(file_path)

            if visual_output.get("error"):
                print(f"âŒ ë¹„ì£¼ì–¼ ë¶„ì„ ì—ëŸ¬: {visual_output['error']}")
            else:
                v_metrics = visual_output.get("metrics", {})

                # ì ìˆ˜ ê³„ì‚° ë¡œì§
                face_ratio = v_metrics.get("face_presence_ratio", 0.0)
                center_ratio = v_metrics.get("head_center_ratio", 0.0)
                score = 100
                feedbacks = []

                if face_ratio < 0.8: score -= 20; feedbacks.append("í™”ë©´ ì´íƒˆì´ ì¦ìŠµë‹ˆë‹¤.")
                if center_ratio < 0.6: score -= 10; feedbacks.append("ê³ ê°œê°€ ì¤‘ì•™ì—ì„œ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤.")

                visual_payload = VisualDBPayload(
                    answer_id=answer_id,
                    score=max(0, score),
                    head_center_ratio=center_ratio,
                    feedback=" ".join(feedbacks) or "ìì„¸ê°€ í›Œë¥­í•©ë‹ˆë‹¤.",
                    good_points_json=[],
                    bad_points_json=[],
                )

                # ğŸŸ¡ [ìˆ˜ì •] Serviceì—ì„œ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
                visual_data = visual_payload.model_dump()
                visual_data['good_points_json'] = json.dumps(visual_data['good_points_json'])
                visual_data['bad_points_json'] = json.dumps(visual_data['bad_points_json'])

                visual_repo.upsert_visual_result(conn, visual_data)
                print(f"âœ… ë¹„ì£¼ì–¼ ë¶„ì„ ì €ì¥ ì™„ë£Œ")


            # =================================================
            # 2. STT ë° ìŒì„± ë¶„ì„
            # =================================================
            print(f"ğŸ—£ï¸ STT ë³€í™˜ ì‹œì‘...")
            stt_output = run_stt(audio_path)
            stt_text = ""
            stt_segments = []
            if not stt_output.get("error"):
                stt_text = stt_output["metrics"].get("text", "")
                stt_segments = stt_output["metrics"].get("segments", [])

            print(f"ğŸ™ï¸ ìŒì„± ë¶„ì„ ì‹œì‘...")
            voice_output = run_voice(audio_path, stt_text=stt_text, stt_segments=stt_segments)

            if voice_output.get("error"):
                print(f"âŒ ìŒì„± ë¶„ì„ ì—ëŸ¬: {voice_output['error']}")
            else:
                metrics = voice_output.get("metrics", {})

                avg_wpm = metrics.get("avg_wpm") or 0
                max_wpm = metrics.get("max_wpm") or 0
                silence_count = metrics.get("silence_count", 0)
                avg_pitch = metrics.get("avg_pitch") or 0.0

                v_score = 100
                good_points = []
                bad_points = []

                if avg_wpm < 80: v_score -= 10; bad_points.append("ë§ì´ ëŠë¦½ë‹ˆë‹¤.")
                elif avg_wpm > 180: v_score -= 10; bad_points.append("ë§ì´ ë¹ ë¦…ë‹ˆë‹¤.")
                else: good_points.append("ì†ë„ê°€ ì ì ˆí•©ë‹ˆë‹¤.")

                if silence_count > 5: v_score -= 10; bad_points.append("ì¹¨ë¬µì´ ì¦ìŠµë‹ˆë‹¤.")
                else: good_points.append("ìì—°ìŠ¤ëŸ½ê²Œ ë§í–ˆìŠµë‹ˆë‹¤.")

                voice_payload = VoiceDBPayload(
                    answer_id=answer_id,
                    score=max(0, v_score),
                    avg_wpm=int(avg_wpm),
                    max_wpm=int(max_wpm),
                    silence_count=int(silence_count),
                    avg_silence_length=0.0,
                    avg_pitch=float(avg_pitch),
                    max_pitch=0.0,
                    silence_timeline_json=[],
                    feedback=" ".join(bad_points) or "í›Œë¥­í•©ë‹ˆë‹¤.",
                    good_points_json=good_points,
                    bad_points_json=bad_points
                )

                # ğŸŸ¡ [ìˆ˜ì •] Serviceì—ì„œ JSON ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ Repoì— ì „ë‹¬
                voice_data = voice_payload.model_dump()
                voice_data['silence_timeline_json'] = json.dumps(voice_data['silence_timeline_json'])
                voice_data['good_points_json'] = json.dumps(voice_data['good_points_json'])
                voice_data['bad_points_json'] = json.dumps(voice_data['bad_points_json'])

                voice_repo.upsert_voice_result(conn, voice_data)
                print(f"âœ… ìŒì„± ë¶„ì„ ì €ì¥ ì™„ë£Œ")


            # =================================================
            # 3. ë‚´ìš© ë¶„ì„ (LLM)
            # =================================================
            print(f"ğŸ“ ë‚´ìš© ë¶„ì„ ì‹œì‘ (LLM)...")

            fillers = ["ìŒ", "ì–´", "ê·¸", "ì•„"]
            filler_count = 0
            if stt_text:
                for f in fillers:
                    filler_count += stt_text.count(f)

            question_text = answer.get("question_content", "")
            duration_sec = stt_segments[-1]["end"] if stt_segments else 0.0

            content_output = run_content(
                answer_text=stt_text,
                question_text=question_text,
                duration_sec=duration_sec
            )

            if content_output.get("error"):
                print(f"âŒ ë‚´ìš© ë¶„ì„ ì—ëŸ¬: {content_output['error']}")
            else:
                c_metrics = content_output.get("metrics", {})

                content_payload = ContentDBPayload(
                    answer_id=answer_id,
                    logic_score=c_metrics.get("logic_score", 0),
                    job_fit_score=c_metrics.get("job_fit_score", 0),
                    time_management_score=c_metrics.get("time_management_score", 0),
                    filler_count=filler_count,
                    keywords_json=c_metrics.get("keywords", []),
                    feedback=c_metrics.get("feedback", ""),
                    model_answer=c_metrics.get("model_answer"),
                    summarized_text=None
                )

                # ğŸŸ¡ [ìˆ˜ì •] Serviceì—ì„œ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
                content_data = content_payload.model_dump()
                content_data['keywords_json'] = json.dumps(content_data['keywords_json'])

                content_repo.upsert_content_result(conn, content_data)
                print(f"âœ… ë‚´ìš© ë¶„ì„ ì €ì¥ ì™„ë£Œ")


            # =================================================
            # âœ… [ì¶”ê°€] 3.5 ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±/ì €ì¥ (Final Report)
            # - visual_output/voice_output/content_output ê¸°ë°˜
            # - session_id ê¸°ì¤€ upsert (ì„¸ì…˜ë‹¹ 1ê°œ)
            # =================================================
            try:
                if session_id:
                    print("ğŸ“Œ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±/ì €ì¥ ì‹œì‘...")

                    # TODO: ë„ˆí¬ í”„ë¡œì íŠ¸ LLM client ê°€ì ¸ì˜¤ëŠ” ë°©ì‹ìœ¼ë¡œ êµì²´
                    # llm_client = llm_client
                    # ë˜ëŠ” llm_client = get_llm_client()

                    llm_client = ReportLLMClient(model="gpt-4o-mini")  # ğŸ‘ˆ ë°˜ë“œì‹œ ì‹¤ì œ llm clientë¡œ ë°”ê¿”ì£¼ì„¸ìš”!

                    final_report_service = FinalReportService(llm_client)
                    final_report_result = final_report_service.create_or_upsert(
                        conn=conn,
                        session_id=session_id,
                        visual_out=visual_output,
                        voice_out=voice_output,
                        content_out=content_output,
                    )
                    print("âœ… ìµœì¢… ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ")
                else:
                    print("âš ï¸ session_idê°€ ì—†ì–´ ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            except Exception as e:
                # final report ì‹¤íŒ¨í•´ë„ ì „ì²´ ë¶„ì„ì€ DONEìœ¼ë¡œ ê°ˆì§€(ê¶Œì¥), FAILEDë¡œ ê°ˆì§€ ì •ì±… ì„ íƒ
                print(f"âš ï¸ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±/ì €ì¥ ì‹¤íŒ¨ (ë¶„ì„ì€ ê³„ì† ì™„ë£Œ ì²˜ë¦¬): {e}")
                traceback.print_exc()


            # 4. ìµœì¢… ì™„ë£Œ ì²˜ë¦¬
            answer_repo.update_analysis_status(conn, answer_id, "DONE")
            print(f"ğŸ‰ [Analysis Done] Answer ID: {answer_id}")

        except Exception as e:
            print(f"ğŸ’¥ [Analysis Failed] Error: {e}")
            traceback.print_exc()
            answer_repo.update_analysis_status(conn, answer_id, "FAILED")


analysis_service = AnalysisService()
