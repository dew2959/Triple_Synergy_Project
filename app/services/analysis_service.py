import traceback
import json
import os
from psycopg2.extensions import connection
from psycopg2.extras import RealDictCursor
from app.utils.media_utils import MediaUtils

# Engines
from app.engines.visual.engine import run_visual
from app.engines.voice.engine import run_voice
from app.engines.stt.engine import run_stt
from app.engines.llm.engine import run_content

# Repositories
from app.repositories.answer_repo import answer_repo
from app.repositories.visual_repo import visual_repo
from app.repositories.voice_repo import voice_repo
from app.repositories.content_repo import content_repo
# [NEW] Final Report Repository
from app.repositories.final_report_repo import final_report_repo

# Services
# [NEW] Final Report Service
from app.services.final_report_service import FinalReportService

# Schemas
from app.schemas.visual import VisualDBPayload
from app.schemas.voice import VoiceDBPayload
from app.schemas.content import ContentDBPayload

# [NEW] LLM Client Adapter for FinalReportService
class OpenAIClientAdapter:
    def generate(self, prompt: str, temperature: float = 0.2) -> str:
        """
        FinalReportServiceê°€ ì‚¬ìš©í•˜ëŠ” ì¸í„°í˜ì´ìŠ¤(generate)ë¥¼ 
        OpenAI SDKì— ë§ì¶° êµ¬í˜„
        """
        try:
            from openai import OpenAI
            client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            response = client.chat.completions.create(
                model="gpt-4o", # ë˜ëŠ” gpt-3.5-turbo
                messages=[{"role": "user", "content": prompt}],
                temperature=temperature,
                response_format={"type": "json_object"} # JSON ê°•ì œ
            )
            return response.choices[0].message.content or "{}"
        except Exception as e:
            print(f"LLM Error: {e}")
            return "{}"

# ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
llm_client = OpenAIClientAdapter()
final_report_service = FinalReportService(llm_client)


class AnalysisService:
    def _get_session_id(self, conn: connection, answer_id: int) -> int:
        """
        answer_idë¥¼ í†µí•´ session_idë¥¼ ì—­ì¶”ì í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
        (answers -> questions -> interview_sessions)
        """
        with conn.cursor() as cur:
            cur.execute("""
                SELECT q.session_id 
                FROM answers a
                JOIN questions q ON a.question_id = q.question_id
                WHERE a.answer_id = %s
            """, (answer_id,))
            row = cur.fetchone()
            if row:
                return row['session_id']
            return None

    def run_full_analysis(self, conn: connection, answer_id: int, file_path: str):
        print(f"ğŸ¬ [Analysis Start] Answer ID: {answer_id}")
        
        # 1. ë‹µë³€ ì¡°íšŒ
        answer = answer_repo.get_by_id(conn, answer_id)
        if not answer:
            print("âŒ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # 2. ìƒíƒœ ë³€ê²½
        print(f"ğŸ”„ ìƒíƒœ ë³€ê²½: PENDING -> PROCESSING")
        answer_repo.update_analysis_status(conn, answer_id, "PROCESSING")

        # ì—”ì§„ ê²°ê³¼ ë‹´ì„ ë³€ìˆ˜ ì´ˆê¸°í™”
        visual_output = {}
        voice_output = {}
        content_output = {}

        try:
            # 0. ì˜¤ë””ì˜¤ ì¶”ì¶œ
            print("ğŸ”Š ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘...")
            audio_path = MediaUtils.extract_audio(file_path)

            # =================================================
            # 1. ë¹„ì£¼ì–¼ ë¶„ì„
            # =================================================
            print(f"ğŸ‘ï¸ ë¹„ì£¼ì–¼ ë¶„ì„ ì‹œì‘...")
            visual_output = run_visual(file_path)
            
            if visual_output.get("error"):
                print(f"âŒ ë¹„ì£¼ì–¼ ë¶„ì„ ì—ëŸ¬: {visual_output['error']}")
            else:
                v_metrics = visual_output.get("metrics", {})
                
                # ë¹„ì£¼ì–¼ ì ìˆ˜ ê³„ì‚° ë¡œì§
                face_ratio = v_metrics.get("face_presence_ratio", 0.0)
                center_ratio = v_metrics.get("head_center_ratio", 0.0)
                score = 100
                feedbacks = []
                
                if face_ratio < 0.8: score -= 20; feedbacks.append("í™”ë©´ ì´íƒˆì´ ì¦ìŠµë‹ˆë‹¤.")
                if center_ratio < 0.6: score -= 10; feedbacks.append("ê³ ê°œê°€ ì¤‘ì•™ì—ì„œ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤.")
                
                visual_payload = VisualDBPayload(
                    answer_id=answer_id,
                    score=max(0, score),
                    head_center_ratio=center_ratio,
                    feedback=" ".join(feedbacks) or "ìì„¸ê°€ í›Œë¥­í•©ë‹ˆë‹¤.",
                    good_points_json=[],
                    bad_points_json=[],
                )
                
                # Serviceì—ì„œ JSON ë¬¸ìì—´ë¡œ ë³€í™˜ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                visual_data = visual_payload.model_dump()
                visual_data['good_points_json'] = json.dumps(visual_data['good_points_json'])
                visual_data['bad_points_json'] = json.dumps(visual_data['bad_points_json'])
                
                visual_repo.upsert_visual_result(conn, visual_data)
                
                # [ì¤‘ìš”] FinalReportServiceì— ë„˜ê²¨ì£¼ê¸° ìœ„í•´ scoreë¥¼ metricsì— ì£¼ì…
                visual_output["metrics"]["score"] = max(0, score)
                print(f"âœ… ë¹„ì£¼ì–¼ ë¶„ì„ ì €ì¥ ì™„ë£Œ")


            # =================================================
            # 2. STT ë° ìŒì„± ë¶„ì„
            # =================================================
            print(f"ğŸ—£ï¸ STT ë³€í™˜ ì‹œì‘...")
            stt_output = run_stt(audio_path)
            stt_text = ""
            stt_segments = []
            if not stt_output.get("error"):
                stt_text = stt_output["metrics"].get("text", "")
                stt_segments = stt_output["metrics"].get("segments", [])

            print(f"ğŸ™ï¸ ìŒì„± ë¶„ì„ ì‹œì‘...")
            voice_output = run_voice(audio_path, stt_text=stt_text, stt_segments=stt_segments)
            
            if voice_output.get("error"):
                 print(f"âŒ ìŒì„± ë¶„ì„ ì—ëŸ¬: {voice_output['error']}")
            else:
                metrics = voice_output.get("metrics", {})
                
                avg_wpm = metrics.get("avg_wpm") or 0
                max_wpm = metrics.get("max_wpm") or 0
                silence_count = metrics.get("silence_count", 0)
                avg_pitch = metrics.get("avg_pitch") or 0.0
                
                v_score = 100
                good_points = []
                bad_points = []
                
                if avg_wpm < 80: v_score -= 10; bad_points.append("ë§ì´ ëŠë¦½ë‹ˆë‹¤.")
                elif avg_wpm > 180: v_score -= 10; bad_points.append("ë§ì´ ë¹ ë¦…ë‹ˆë‹¤.")
                else: good_points.append("ì†ë„ê°€ ì ì ˆí•©ë‹ˆë‹¤.")

                if silence_count > 5: v_score -= 10; bad_points.append("ì¹¨ë¬µì´ ì¦ìŠµë‹ˆë‹¤.")
                else: good_points.append("ìì—°ìŠ¤ëŸ½ê²Œ ë§í–ˆìŠµë‹ˆë‹¤.")

                voice_payload = VoiceDBPayload(
                    answer_id=answer_id,
                    score=max(0, v_score),
                    avg_wpm=int(avg_wpm),
                    max_wpm=int(max_wpm),
                    silence_count=int(silence_count),
                    avg_silence_length=0.0,
                    avg_pitch=float(avg_pitch),
                    max_pitch=0.0,
                    silence_timeline_json=[],
                    feedback=" ".join(bad_points) or "í›Œë¥­í•©ë‹ˆë‹¤.",
                    good_points_json=good_points,
                    bad_points_json=bad_points
                )
                
                voice_data = voice_payload.model_dump()
                voice_data['silence_timeline_json'] = json.dumps(voice_data['silence_timeline_json'])
                voice_data['good_points_json'] = json.dumps(voice_data['good_points_json'])
                voice_data['bad_points_json'] = json.dumps(voice_data['bad_points_json'])

                voice_repo.upsert_voice_result(conn, voice_data)
                
                # [ì¤‘ìš”] FinalReportServiceìš© ì ìˆ˜ ì£¼ì…
                voice_output["metrics"]["score"] = max(0, v_score)
                print(f"âœ… ìŒì„± ë¶„ì„ ì €ì¥ ì™„ë£Œ")


            # =================================================
            # 3. ë‚´ìš© ë¶„ì„ (LLM)
            # =================================================
            print(f"ğŸ“ ë‚´ìš© ë¶„ì„ ì‹œì‘ (LLM)...")
            
            fillers = ["ìŒ", "ì–´", "ê·¸", "ì•„"]
            filler_count = 0
            if stt_text:
                for f in fillers: filler_count += stt_text.count(f)

            question_text = answer.get("question_content", "") 
            duration_sec = stt_segments[-1]["end"] if stt_segments else 0.0

            content_output = run_content(
                answer_text=stt_text,
                question_text=question_text,
                duration_sec=duration_sec
            )

            if content_output.get("error"):
                print(f"âŒ ë‚´ìš© ë¶„ì„ ì—ëŸ¬: {content_output['error']}")
            else:
                c_metrics = content_output.get("metrics", {})
                
                # ì¢…í•© ì ìˆ˜ ê³„ì‚° (Content Engineì´ ì•ˆ ì£¼ë©´ í‰ê· ìœ¼ë¡œ ê³„ì‚°)
                l_score = c_metrics.get("logic_score", 0)
                j_score = c_metrics.get("job_fit_score", 0)
                t_score = c_metrics.get("time_management_score", 0)
                # ë§Œì•½ metricsì— 'score'ê°€ ì—†ë‹¤ë©´ ì„ì˜ ê³„ì‚°
                final_content_score = int((l_score + j_score + t_score) / 3)
                
                content_payload = ContentDBPayload(
                    answer_id=answer_id,
                    score=final_content_score, # ì—¬ê¸°ì— ì ìˆ˜ í•„ìš”
                    logic_score=l_score,
                    job_fit_score=j_score,
                    time_management_score=t_score,
                    filler_count=filler_count,
                    keywords_json=c_metrics.get("keywords", []),
                    feedback=c_metrics.get("feedback", ""),
                    model_answer=c_metrics.get("model_answer"),
                    summarized_text=None
                )
                
                content_data = content_payload.model_dump()
                content_data['keywords_json'] = json.dumps(content_data['keywords_json'])
                
                content_repo.upsert_content_result(conn, content_data)
                
                # [ì¤‘ìš”] FinalReportServiceìš© ì ìˆ˜ ì£¼ì…
                content_output["metrics"]["score"] = final_content_score
                print(f"âœ… ë‚´ìš© ë¶„ì„ ì €ì¥ ì™„ë£Œ")


            # =================================================
            # 4. Final Report ìƒì„± (ì¢…í•© ë¶„ì„)
            # =================================================
            print(f"ğŸ“Š ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘...")
            
            # (1) Session ID ì¡°íšŒ
            session_id = self._get_session_id(conn, answer_id)
            
            if session_id:
                # (2) ë¦¬í¬íŠ¸ ìƒì„± ë° ì €ì¥ (Upsert)
                # ì´ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ LLM í˜¸ì¶œ -> JSON íŒŒì‹± -> DB ì €ì¥ì´ ì¼ì–´ë‚©ë‹ˆë‹¤.
                report_result = final_report_service.create_or_upsert(
                    conn=conn,
                    session_id=session_id,
                    visual_out=visual_output,
                    voice_out=voice_output,
                    content_out=content_output
                )
                print(f"âœ… ì¢…í•© ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ (Total Score: {report_result.total_score})")
            else:
                print(f"âš ï¸ Session IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¢…í•© ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")


            # 5. ìµœì¢… ì™„ë£Œ ì²˜ë¦¬
            answer_repo.update_analysis_status(conn, answer_id, "DONE")
            print(f"ğŸ‰ [Analysis Done] Answer ID: {answer_id}")

        except Exception as e:
            print(f"ğŸ’¥ [Analysis Failed] Error: {e}")
            traceback.print_exc()
            answer_repo.update_analysis_status(conn, answer_id, "FAILED")

analysis_service = AnalysisService()