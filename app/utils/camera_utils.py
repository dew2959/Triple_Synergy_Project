import cv2
import numpy as np
import tempfile
from streamlit_webrtc import VideoTransformerBase

# OpenCV Haar Cascade ì–¼êµ´ íƒì§€
face_cascade = cv2.CascadeClassifier(
    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
)

class FaceGuideTransformer(VideoTransformerBase):
    """
    ì‹¤ì‹œê°„ ì›¹ìº  ì˜ìƒì— ì–¼êµ´ ê°€ì´ë“œ ì› í‘œì‹œ
    ì–¼êµ´ì´ ì› ì•ˆì— ë“¤ì–´ì˜¤ë©´ ì´ˆë¡, ì•„ë‹ˆë©´ ë¹¨ê°•
    ë…¹í™” ê¸°ëŠ¥ë„ ì§€ì›
    """
    def __init__(self):
        self.recorded_frames = []  # ë…¹í™”ìš© í”„ë ˆì„ ì €ì¥

    def recv(self, frame):
        # í”„ë ˆì„ ë³€í™˜
        img = frame.to_ndarray(format="bgr24")
        h, w, _ = img.shape

        # í™”ë©´ ì¤‘ì•™ ì› ì¢Œí‘œ
        center_x, center_y = w // 2, int(h * 0.45)
        radius = int(w * 0.18)

        # ì–¼êµ´ ê°ì§€
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)

        is_inside = False

        if len(faces) > 0:
            # ê°€ì¥ í° ì–¼êµ´ í•˜ë‚˜ë§Œ ì‚¬ìš©
            x, y, fw, fh = max(faces, key=lambda f: f[2]*f[3])
            face_x = x + fw // 2
            face_y = y + fh // 2

            distance = np.sqrt((face_x - center_x) ** 2 + (face_y - center_y) ** 2)
            if distance < radius * 0.5:
                is_inside = True

            # ì–¼êµ´ ìœ„ì¹˜ í‘œì‹œ
            color = (0, 255, 0) if is_inside else (0, 0, 255)
            cv2.rectangle(img, (x, y), (x+fw, y+fh), color, 2)

        # ì¤‘ì•™ ì› ê·¸ë¦¬ê¸°
        color = (0, 255, 0) if is_inside else (0, 0, 255)
        cv2.circle(img, (center_x, center_y), radius, color, 4)

        # ìƒíƒœ í…ìŠ¤íŠ¸
        text = "ìœ„ì¹˜ ì ì ˆ âœ…" if is_inside else "ì–¼êµ´ì„ ì› ì•ˆìœ¼ë¡œ ì´ë™ ğŸŸ¥"
        cv2.putText(img, text, (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)

        # ë…¹í™”ìš©ìœ¼ë¡œ í”„ë ˆì„ ì €ì¥
        self.recorded_frames.append(img)

        return img

    def get_recorded_video(self):
        """
        ë…¹í™”ëœ í”„ë ˆì„ì„ mp4ë¡œ ì €ì¥ í›„ íŒŒì¼ ê²½ë¡œ ë°˜í™˜
        """
        if not self.recorded_frames:
            return None

        tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4").name
        h, w, _ = self.recorded_frames[0].shape
        out = cv2.VideoWriter(tmp_file, cv2.VideoWriter_fourcc(*'mp4v'), 30, (w, h))
        for frame in self.recorded_frames:
            out.write(frame)
        out.release()

        # ë…¹í™” ì´ˆê¸°í™”
        self.recorded_frames = []
        return tmp_file
