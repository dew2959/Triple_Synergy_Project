import os
import cv2
import math
import numpy as np
import mediapipe as mp
from typing import Dict, Any, List
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

# í”„ë¡œì íŠ¸ ì„¤ì • (í•„ìš” ì‹œ ì‚¬ìš©)
from app.core.config import settings

# =========================================================
# âš™ï¸ V3 ì±„ì  ê¸°ì¤€ ìƒìˆ˜ ì„¤ì •
# =========================================================
# [1] Head (ê³ ê°œ ê°ë„)
HEAD_NORMAL_THRESHOLD = 2.5   # ì •ìƒ ë²”ìœ„ (Â±2.5ë„)
HEAD_MINOR_THRESHOLD = 10.0   # ê²½ë¯¸/ì‹¬ê° ê²½ê³„ (10ë„)
HEAD_MINOR_TIME_LIMIT = 3.0   # ê²½ë¯¸í•œ ì´íƒˆ í—ˆìš© ì‹œê°„ (3ì´ˆ)
HEAD_MINOR_ALLOW_COUNT = 3    # ê²½ë¯¸í•œ ì´íƒˆ í—ˆìš© íšŸìˆ˜
HEAD_MAJOR_ALLOW_COUNT = 1    # ì‹¬ê°í•œ ì´íƒˆ í—ˆìš© íšŸìˆ˜

# [2] Smile (ë¯¸ì†Œ)
SMILE_THRESHOLD = 0.5         # ë¯¸ì†Œ ê°ì§€ ìž„ê³„ê°’ (Blendshape)

# [3] Blink (ëˆˆ ê¹œë¹¡ìž„)
BLINK_THRESHOLD = 0.5         # ëˆˆ ê°ìŒ ìž„ê³„ê°’
BLINK_RPM_MIN = 10            # ì •ìƒ ìµœì†Œ RPM
BLINK_RPM_MAX = 30            # ì •ìƒ ìµœëŒ€ RPM

# [4] Gaze (ì‹œì„ )
GAZE_OFF_RATIO_LIMIT = 0.10   # ì „ì²´ ì‹œê°„ ëŒ€ë¹„ í—ˆìš© ì´íƒˆ ë¹„ìœ¨ (10%)
GAZE_LONG_DURATION = 2.0      # ìž¥ê¸° ì´íƒˆ ê¸°ì¤€ ì‹œê°„ (2ì´ˆ)

# MediaPipe ëª¨ë¸ ê²½ë¡œ
MODEL_PATH = os.path.join(os.getcwd(), "app", "engines", "visual", "models", "face_landmarker.task")

class VisualAnalysisEngine:
    def __init__(self):
        if not os.path.exists(MODEL_PATH):
            raise FileNotFoundError(f"MediaPipe Model not found at: {MODEL_PATH}")

    # ---------------------------------------------------------
    # ðŸ“ ìˆ˜í•™/ê¸°í•˜í•™ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
    # ---------------------------------------------------------
    def _calculate_head_angle(self, p_nose, p_head) -> float:
        """ì½”(Nose)ì™€ ì •ìˆ˜ë¦¬(HeadTop) ì¢Œí‘œë¥¼ ì´ìš©í•´ ê³ ê°œ ê¸°ìš¸ê¸°(Roll) ê³„ì‚°"""
        dx = p_head.x - p_nose.x
        dy = p_head.y - p_nose.y
        # ì˜ìƒ ì¢Œí‘œê³„(yê°€ ì•„ëž˜ë¡œ) ê³ ë ¤
        angle_rad = math.atan2(dy, dx)
        angle_deg = math.degrees(angle_rad) + 90
        return angle_deg

    def _get_iris_shift(self, landmarks, w, h) -> float:
        """ëˆˆë™ìž(Iris) ìœ„ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œì„  ì´íƒˆ ì •ë„ ê³„ì‚°"""
        # ëžœë“œë§ˆí¬ ì¸ë±ìŠ¤
        L_OUTER, L_INNER = 33, 133
        R_OUTER, R_INNER = 263, 362
        L_IRIS = [468, 469, 470, 471, 472]
        R_IRIS = [473, 474, 475, 476, 477]

        def _to_px(lm): return np.array([lm.x * w, lm.y * h])
        
        def _get_center(idxs):
            pts = [_to_px(landmarks[i]) for i in idxs]
            return np.mean(pts, axis=0)

        def _calc_shift(iris_c, outer_idx, inner_idx):
            p_out = _to_px(landmarks[outer_idx])
            p_in = _to_px(landmarks[inner_idx])
            eye_width = np.linalg.norm(p_in - p_out) + 1e-6
            eye_center = (p_out + p_in) * 0.5
            eye_vec = (p_in - p_out) / eye_width
            
            # íˆ¬ì˜(Projection)ì„ í†µí•´ ì¤‘ì‹¬ìœ¼ë¡œë¶€í„° ê±°ë¦¬ ê³„ì‚°
            rel = iris_c - eye_center
            shift = float(np.dot(rel, eye_vec)) / eye_width
            return shift

        try:
            iris_l_c = _get_center(L_IRIS)
            iris_r_c = _get_center(R_IRIS)
            
            shift_l = _calc_shift(iris_l_c, L_OUTER, L_INNER)
            shift_r = _calc_shift(iris_r_c, R_OUTER, R_INNER)
            
            # ë‘ ëˆˆ ì¤‘ ë” í¬ê²Œ ì´íƒˆí•œ ê°’ì„ ë°˜í™˜
            return max(abs(shift_l), abs(shift_r))
        except:
            return 0.0

    # ---------------------------------------------------------
    # ðŸš€ ë©”ì¸ ë¶„ì„ ë¡œì§
    # ---------------------------------------------------------
    def analyze(self, video_path: str) -> Dict[str, Any]:
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return {"error": "Failed to open video file"}
        base_options = python.BaseOptions(model_asset_path=MODEL_PATH)
        options = vision.FaceLandmarkerOptions(
            base_options=base_options,
            running_mode=vision.RunningMode.VIDEO, # ë¹„ë””ì˜¤ ëª¨ë“œ
            num_faces=1,
            output_face_blendshapes=True,
            output_facial_transformation_matrixes=True
        )
        landmarker = vision.FaceLandmarker.create_from_options(options)
        fps = cap.get(cv2.CAP_PROP_FPS) or 30
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration_sec = frame_count / fps if fps > 0 else 0

        # ì‹œê³„ì—´ ë°ì´í„° ì €ìž¥ì†Œ
        history = {
            "timestamps": [],
            "head_angles": [],
            "gaze_shifts": [],
            "blink_scores": [],
            "smile_scores": []
        }
        try :
            # 1ï¸âƒ£ í”„ë ˆìž„ ë‹¨ìœ„ ë°ì´í„° ì¶”ì¶œ
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                timestamp_ms = int(cap.get(cv2.CAP_PROP_POS_MSEC))
                h, w, _ = frame.shape
                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                mp_img = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb)

                result = landmarker.detect_for_video(mp_img, timestamp_ms)

                # ê¸°ë³¸ê°’ (ê°ì§€ ì•ˆë  ê²½ìš°)
                angle = 0.0
                gaze_shift = 0.0
                blink_sc = 0.0
                smile_sc = 0.0

                if result.face_landmarks:
                    landmarks = result.face_landmarks[0]
                    blendshapes = result.face_blendshapes[0]

                    # (1) Head Angle
                    nose = landmarks[1]
                    head_top = landmarks[10]
                    angle = self._calculate_head_angle(nose, head_top)

                    # (2) Gaze Shift
                    gaze_shift = self._get_iris_shift(landmarks, w, h)

                    # (3) Blendshapes (Blink & Smile)
                    # MediaPipe Blendshape ì´ë¦„ ë§¤í•‘
                    bs_dict = {b.category_name: b.score for b in blendshapes}
                    blink_sc = (bs_dict.get('eyeBlinkLeft', 0) + bs_dict.get('eyeBlinkRight', 0)) / 2.0
                    smile_sc = (bs_dict.get('mouthSmileLeft', 0) + bs_dict.get('mouthSmileRight', 0)) / 2.0

                history["timestamps"].append(timestamp_ms / 1000.0) # sec
                history["head_angles"].append(angle)
                history["gaze_shifts"].append(gaze_shift)
                history["blink_scores"].append(blink_sc)
                history["smile_scores"].append(smile_sc)

        except Exception as e:
            print(f"MediaPipe Process Error: {e}")
            return {"error": str(e)}
        
        finally:
            # ðŸŸ¢ [ìˆ˜ì • 3] ì‚¬ìš© í›„ ë°˜ë“œì‹œ ë¦¬ì†ŒìŠ¤ í•´ì œ
            cap.release()
            landmarker.close()

        # 2ï¸âƒ£ V3 ì±„ì  ë¡œì§ ì ìš©
        return self._calculate_v3_score(history, duration_sec)

    def _calculate_v3_score(self, h: Dict[str, List[float]], duration: float) -> Dict[str, Any]:
        if duration <= 0:
            return {"score": 0, "feedback": "ì˜ìƒ ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤."}

        # --- ì ìˆ˜íŒ ì´ˆê¸°í™” ---
        scores = {
            "head": 50,
            "smile": 0,  # ê¸°ë³¸ 0, ê°ì§€ì‹œ +5
            "blink": 10,
            "gaze": 20,
            "base": 15
        }
        deductions = [] # ê°ì  ì‚¬ìœ  ê¸°ë¡

        # =========================================================
        # [1] Head Logic (50ì  ë§Œì )
        # =========================================================
        # 2.5ë„ ~ 10ë„ (Minor), 10ë„ ì´ìƒ (Major)
        minor_events = [] # duration list
        major_events = [] # duration list
        
        curr_state = "NORMAL" # NORMAL, MINOR, MAJOR
        start_time = 0
        
        times = h["timestamps"]
        angles = h["head_angles"]

        for i, t in enumerate(times):
            abs_ang = abs(angles[i])
            
            # ìƒíƒœ íŒë‹¨
            if abs_ang >= HEAD_MINOR_THRESHOLD:
                new_state = "MAJOR"
            elif abs_ang >= HEAD_NORMAL_THRESHOLD:
                new_state = "MINOR"
            else:
                new_state = "NORMAL"

            # ìƒíƒœ ë³€í™” ì²˜ë¦¬ (ì´ë²¤íŠ¸ ì¢…ë£Œ ë° ê¸°ë¡)
            if new_state != curr_state:
                if curr_state != "NORMAL":
                    dur = t - start_time
                    if curr_state == "MINOR": minor_events.append(dur)
                    if curr_state == "MAJOR": major_events.append(dur)
                
                start_time = t
                curr_state = new_state
        
        # ë§ˆì§€ë§‰ ìƒíƒœ ì²˜ë¦¬
        if curr_state != "NORMAL":
            dur = times[-1] - start_time
            if curr_state == "MINOR": minor_events.append(dur)
            if curr_state == "MAJOR": major_events.append(dur)

        # -- Head ì ìˆ˜ ê³„ì‚° --
        head_deduction = 0
        
        # Minor Logic: 3ì´ˆ ì´ˆê³¼ -> ì¦‰ì‹œ -10 (ë¶ˆì•ˆì •). 3ì´ˆ ì´í•˜ -> 3íšŒ í—ˆìš© í›„ -5/íšŒ
        minor_short_count = 0
        for dur in minor_events:
            if dur > HEAD_MINOR_TIME_LIMIT:
                head_deduction += 10
                deductions.append(f"ê³ ê°œ ê²½ë¯¸ ì´íƒˆ 3ì´ˆ ì´ìƒ ì§€ì† (-10ì )")
            else:
                minor_short_count += 1
        
        if minor_short_count > HEAD_MINOR_ALLOW_COUNT:
            penalty_count = minor_short_count - HEAD_MINOR_ALLOW_COUNT
            ded = penalty_count * 5
            head_deduction += ded
            deductions.append(f"ê³ ê°œ ê²½ë¯¸ ì´íƒˆ íšŸìˆ˜ ì´ˆê³¼({penalty_count}íšŒ) (-{ded}ì )")

        # Major Logic: 1íšŒ í—ˆìš©, ì´í›„ -20/íšŒ
        if len(major_events) > HEAD_MAJOR_ALLOW_COUNT:
            penalty_count = len(major_events) - HEAD_MAJOR_ALLOW_COUNT
            ded = penalty_count * 20
            head_deduction += ded
            deductions.append(f"ê³ ê°œ ì‹¬ê°í•œ ì´íƒˆ íšŸìˆ˜ ì´ˆê³¼({penalty_count}íšŒ) (-{ded}ì )")

        # ìµœëŒ€ ê°ì  -50
        scores["head"] = max(0, 50 - min(50, head_deduction))


        # =========================================================
        # [2] Smile Logic (5ì  ë§Œì )
        # =========================================================
        # í•œë²ˆì´ë¼ë„ 0.5 ì´ìƒì´ë©´ +5
        max_smile = max(h["smile_scores"]) if h["smile_scores"] else 0
        if max_smile >= SMILE_THRESHOLD:
            scores["smile"] = 5
        else:
            deductions.append("ë¯¸ì†Œê°€ ê°ì§€ë˜ì§€ ì•ŠìŒ (0/5ì )")


        # =========================================================
        # [3] Blink Logic (10ì  ë§Œì )
        # =========================================================
        # Blink Count (Rising Edge ê°ì§€)
        blink_cnt = 0
        is_closed = False
        for s in h["blink_scores"]:
            if s > BLINK_THRESHOLD:
                if not is_closed:
                    blink_cnt += 1
                    is_closed = True
            else:
                is_closed = False
        
        rpm = blink_cnt / (duration / 60.0) if duration > 0 else 0
        
        if rpm < BLINK_RPM_MIN: # ë„ˆë¬´ ì ê²Œ ê¹œë¹¡ìž„ (ê¸´ìž¥/ê²½ì§)
            if rpm < 5: # ì‹¬ê°
                scores["blink"] -= 10
                deductions.append(f"ëˆˆ ê¹œë¹¡ìž„ì´ ë§¤ìš° ë¶€ì¡±í•¨({rpm:.1f}íšŒ/ë¶„) (-10ì )")
            else:
                scores["blink"] -= 5
                deductions.append(f"ëˆˆ ê¹œë¹¡ìž„ ë¶€ì¡±({rpm:.1f}íšŒ/ë¶„) (-5ì )")
        elif rpm > BLINK_RPM_MAX: # ë„ˆë¬´ ë§Žì´ ê¹œë¹¡ìž„ (ë¶ˆì•ˆ)
            if rpm > 50: # ì‹¬ê°
                scores["blink"] -= 10
                deductions.append(f"ëˆˆ ê¹œë¹¡ìž„ì´ ê³¼ë„í•¨({rpm:.1f}íšŒ/ë¶„) (-10ì )")
            else:
                scores["blink"] -= 5
                deductions.append(f"ëˆˆ ê¹œë¹¡ìž„ ë‹¤ì†Œ ê³¼í•¨({rpm:.1f}íšŒ/ë¶„) (-5ì )")
        
        scores["blink"] = max(0, scores["blink"]) # 0ì  ë¯¸ë§Œ ë°©ì§€


        # =========================================================
        # [4] Gaze Logic (20ì  ë§Œì )
        # =========================================================
        GAZE_THRESH = 0.15 # íŠœë‹ê°’ (ì´ ì •ë„ shiftë©´ ì´íƒˆë¡œ ê°„ì£¼)
        
        gaze_off_frames = 0
        long_gaze_events = 0
        current_gaze_dur = 0
        
        for shift in h["gaze_shifts"]:
            if shift > GAZE_THRESH:
                gaze_off_frames += 1
                current_gaze_dur += 1
            else:
                # ì´íƒˆ ì¢…ë£Œ ì‹œ ìž¥ê¸° ì—¬ë¶€ ì²´í¬
                if current_gaze_dur > 0:
                    # í”„ë ˆìž„ ìˆ˜ -> ì‹œê°„ ë³€í™˜ í•„ìš” (ì—¬ê¸°ì„  ì•½ì‹ìœ¼ë¡œ í”„ë ˆìž„ê°„ê²© í‰ê·  ì‚¬ìš©)
                    # ì •í™•ížˆ í•˜ë ¤ë©´ timestamp ì°¸ì¡°í•´ì•¼ í•¨. ì•½ì‹ ë¡œì§:
                    dt = duration / len(h["timestamps"])
                    sec = current_gaze_dur * dt
                    if sec > GAZE_LONG_DURATION:
                        long_gaze_events += 1
                current_gaze_dur = 0
        
        total_score = 100
        # ì ìˆ˜ ê³„ì‚°
        ratio = gaze_off_frames / len(h["timestamps"]) if h["timestamps"] else 0
        
        # ì „ì²´ ì´íƒˆ ë¹„ìœ¨ 10% ì´ìƒ -> -10
        if ratio >= GAZE_OFF_RATIO_LIMIT:
            scores["gaze"] -= 10
            deductions.append(f"ì‹œì„  ë¶ˆì•ˆì • ë¹„ìœ¨ ë†’ìŒ({ratio*100:.1f}%) (-10ì )")
        
        # ìž¥ê¸° ì´íƒˆ íšŸìˆ˜ë‹¹ -5 (ìµœëŒ€ -10)
        if long_gaze_events > 0:
            ded = min(10, long_gaze_events * 5)
            scores["gaze"] -= ded
            deductions.append(f"2ì´ˆ ì´ìƒ ì‹œì„  ì´íƒˆ {long_gaze_events}íšŒ (-{ded}ì )")

        scores["gaze"] = max(0, scores["gaze"])


        # =========================================================
        # ðŸ“ ìµœì¢… ê²°ê³¼ ì§‘ê³„
        # =========================================================
        final_score = sum(scores.values())
        
        summary = ""
        if final_score >= 90: summary = "ë§¤ìš° ì•ˆì •ì ì´ê³  í›Œë¥­í•œ ë¹„ì–¸ì–´ì  íƒœë„ìž…ë‹ˆë‹¤."
        elif final_score >= 70: summary = "ì „ë°˜ì ìœ¼ë¡œ ì–‘í˜¸í•˜ë‚˜ ì¼ë¶€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤."
        else: summary = "ì‹œì„  ì²˜ë¦¬ì™€ ìžì„¸ì—ì„œ ë¶ˆì•ˆì •í•œ ëª¨ìŠµì´ ë³´ìž…ë‹ˆë‹¤."

        # í”¼ë“œë°± ë¬¸ìžì—´ ìƒì„±
        feedback_str = summary
        if deductions:
            feedback_str += "\n\n[ì£¼ìš” ê°ì  ìš”ì¸]\n- " + "\n- ".join(deductions[:3]) # ìƒìœ„ 3ê°œë§Œ

        return {
            "score": int(final_score),
            "feedback": feedback_str,
            "details": {
                "head_score": scores["head"],
                "smile_score": scores["smile"],
                "blink_score": scores["blink"],
                "gaze_score": scores["gaze"],
                "rpm": round(rpm, 1),
                "timeline_timestamps": h["timestamps"][::15], # ê·¸ëž˜í”„ìš© (ë°ì´í„° ì¤„ìž„)
                "timeline_head": h["head_angles"][::15]
            }
        }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_visual_engine = VisualAnalysisEngine()

def run_visual(video_path:str) -> Dict[str, Any]:
    return _visual_engine.analyze(video_path)